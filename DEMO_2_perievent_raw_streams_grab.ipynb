{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "\n",
    "from harp_resources import process, utils\n",
    "from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/home/ikharitonov/RANCZLAB-NAS/data/ONIX/20240730_Mismatch_Experiment/GRAB_MMclosed&Regular_220824/2024-08-22T13-13-15_B3M6')\n",
    "photometry_path = Path('/home/ikharitonov/RANCZLAB-NAS/data/ONIX/20240730_Mismatch_Experiment/GRAB_MMclosed&Regular_220824/photometry/B3M6_MMclosed&Regular_day1/2024_08_22-15_16_40')\n",
    "#preprocessed photometry data should go in the same folder, currently manually matched with Hilde's google drive "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Videography and SLEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lp.create_flipped_videos(data_path, what_to_flip='VideoData1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoData1, VideoData2 = lp.load_videography_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLEAP processing\n",
    "\n",
    "VideoData2 = VideoData2.interpolate()\n",
    "\n",
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "coordinates_dict = lp.get_coordinates_dict(VideoData2, columns_of_interest)\n",
    "\n",
    "theta = lp.find_horizontal_axis_angle(VideoData2, 'left', 'center')\n",
    "center_point = lp.get_left_right_center_point(coordinates_dict)\n",
    "\n",
    "columns_of_interest = ['left', 'right', 'center', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "remformatted_coordinates_dict = lp.get_reformatted_coordinates_dict(coordinates_dict, columns_of_interest)\n",
    "centered_coordinates_dict = lp.get_centered_coordinates_dict(remformatted_coordinates_dict, center_point)\n",
    "rotated_coordinates_dict = lp.get_rotated_coordinates_dict(centered_coordinates_dict, theta)\n",
    "\n",
    "columns_of_interest = ['p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "ellipse_parameters_data, ellipse_center_points_data = lp.get_fitted_ellipse_parameters(rotated_coordinates_dict, columns_of_interest)\n",
    "\n",
    "SleapData = process.convert_arrays_to_dataframe(['Seconds', 'Ellipse.Width', 'Ellipse.Height', 'Ellipse.Angle', 'Ellipse.Center.X', 'Ellipse.Center.Y'], [VideoData2['Seconds'].values, ellipse_parameters_data[:,0], ellipse_parameters_data[:,1], ellipse_parameters_data[:,2], ellipse_center_points_data[:,0], ellipse_center_points_data[:,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Loading and Synchronisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversions = process.calculate_conversions_second_approach(data_path, photometry_path, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "streams = utils.load_registers(data_path)\n",
    "\n",
    "# Photometry = utils.read_fluorescence(photometry_path)\n",
    "Photometry = pd.read_csv('/home/ikharitonov/Downloads/preprocessed_grab2.csv')\n",
    "Photometry['TimeStamp'] = Photometry['TimeStamp'] * 1000\n",
    "Photometry['HARP Timestamps'] = conversions['photometry_to_harp_time'](Photometry['TimeStamp'])\n",
    "\n",
    "streams = process.reformat_and_add_many_streams(streams, Photometry, 'Photometry', ['470_dfF'], index_column_name='HARP Timestamps')\n",
    "streams = process.reformat_and_add_many_streams(streams, SleapData, 'Eye Movements', ['Ellipse.Width', 'Ellipse.Height', 'Ellipse.Angle', 'Ellipse.Center.X', 'Ellipse.Center.Y'])\n",
    "\n",
    "_ = process.get_timepoint_info(streams, print_all=True)\n",
    "resampled_streams = process.pad_and_resample(streams, resampling_period='0.1ms', method='linear')\n",
    "_ = process.get_timepoint_info(resampled_streams, print_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "OnixAnalogClock = utils.read_OnixAnalogClock(data_path)\n",
    "OnixAnalogData = utils.read_OnixAnalogData(data_path, binarise=True)\n",
    "ExperimentEvents = utils.read_ExperimentEvents(data_path)\n",
    "\n",
    "# Selecting desired HARP times, applying conversion to ONIX time\n",
    "start_harp_time_of_halt_one = ExperimentEvents[ExperimentEvents.Value=='Apply halt: 1s'].iloc[0].Seconds\n",
    "start_harp_time_of_halt_four = ExperimentEvents[ExperimentEvents.Value=='Apply halt: 1s'].iloc[3].Seconds\n",
    "\n",
    "# Selecting photodiode times and data within the range, converting back to HARP and plotting\n",
    "selected_harp_times, selected_photodiode_data = process.select_from_photodiode_data(OnixAnalogClock, OnixAnalogData, start_harp_time_of_halt_one - 1, start_harp_time_of_halt_four, conversions)\n",
    "\n",
    "plt.plot(selected_harp_times, selected_photodiode_data[:, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD CSV FILE SAVED FROM STEP 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_avarage_smoothing(X,k):\n",
    "    S = np.zeros(X.shape[0])\n",
    "    for t in range(X.shape[0]):\n",
    "        if t < k:\n",
    "            S[t] = np.mean(X[:t+1])\n",
    "        else:\n",
    "            S[t] = np.sum(X[t-k:t])/k\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "running = resampled_streams['H1']['OpticalTrackingRead0X(46)']\n",
    "# running = moving_avarage_smoothing(running,50)\n",
    "photometry = resampled_streams['Photometry']['470_dfF']\n",
    "eye_movements = resampled_streams['Eye Movements']['Ellipse.Center.X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_unit_conversion(running_array):\n",
    "    resolution = 12000 # counts per inch\n",
    "    inches_per_count = 1 / resolution\n",
    "    meters_per_count = 0.0254 * inches_per_count\n",
    "    dt = 0.01 # for OpticalTrackingRead0Y(46)\n",
    "    linear_velocity = meters_per_count / dt # meters per second per count\n",
    "    \n",
    "    # ball_radius = 0.1 # meters \n",
    "    # angular_velocity = linear_velocity / ball_radius # radians per second per count\n",
    "    # angular_velocity = angular_velocity * (180 / np.pi) # degrees per second per count\n",
    "    # print(angular_velocity)\n",
    "\n",
    "    return running_array * linear_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "running = running_unit_conversion(running) # meters per second\n",
    "running *= 100 # centimeters per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A = None\n",
    "#B = None\n",
    "A = 353590\n",
    "B = A + 30\n",
    "\n",
    "# photodiode_x, photodiode_y = process.select_from_photodiode_data(OnixAnalogClock, OnixAnalogData, A, B, conversions)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, ncols=1, figsize=(12,24))\n",
    "\n",
    "t = (eye_movements.index - utils.harp.REFERENCE_EPOCH).total_seconds()\n",
    "\n",
    "ax[0].plot(t, running)\n",
    "ax[0].set_title('Running')\n",
    "ax[0].set_xlim([A,B])\n",
    "ax[0].set_xlabel('time (seconds)')\n",
    "ax[0].set_ylabel('running speed (cm/s)')\n",
    "\n",
    "ax[1].plot(t, photometry)\n",
    "ax[1].set_title('CH1-470')\n",
    "ax[1].set_xlim([A,B])\n",
    "ax[1].set_xlabel('time (seconds)')\n",
    "ax[1].set_ylabel('signal magnitude')\n",
    "\n",
    "# ax[1].plot(t, resampled_streams['H2']['Encoder(38)'])\n",
    "# ax[1].set_title('CH1-470')\n",
    "# ax[1].set_xlim([A,B])\n",
    "# ax[1].set_xlabel('time (seconds)')\n",
    "# ax[1].set_ylabel('signal magnitude')\n",
    "\n",
    "ax[2].plot(t, eye_movements)\n",
    "ax[2].set_title('Eye Movements')\n",
    "ax[2].set_xlim([A,B])\n",
    "ax[2].set_xlabel('time (seconds)')\n",
    "ax[2].set_ylabel('horizontal eye position (pixels)')\n",
    "\n",
    "ax[3].plot(t, resampled_streams['Eye Movements']['Ellipse.Center.Y'])\n",
    "ax[3].set_title('Eye Movements')\n",
    "ax[3].set_xlim([A,B])\n",
    "ax[3].set_xlabel('time (seconds)')\n",
    "ax[3].set_ylabel('vertical eye position (pixels)')\n",
    "\n",
    "# ax[3].plot(process.convert_datetime_to_seconds(photodiode_x), photodiode_y[:,0])\n",
    "# ax[3].set_title('Photodiode')\n",
    "# ax[3].set_xlim([A,B])\n",
    "# ax[3].set_xlabel('time (seconds)')\n",
    "# ax[3].set_ylabel('photodiode signal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentEvents.Value.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentEvents = utils.read_ExperimentEvents(data_path)\n",
    "\n",
    "# A = ExperimentEvents[ExperimentEvents.Value=='Apply halt: 1s'].iloc[0].Seconds\n",
    "# B = ExperimentEvents[ExperimentEvents.Value=='Apply halt: 1s'].iloc[-1].Seconds\n",
    "\n",
    "# A = ExperimentEvents.iloc[0].Seconds\n",
    "# B = ExperimentEvents.iloc[-1].Seconds\n",
    "\n",
    "A = ExperimentEvents[ExperimentEvents.Value=='LinearMismatch block started'].iloc[0].Seconds #move this to the top (first cell)\n",
    "B = ExperimentEvents.iloc[-1].Seconds\n",
    "\n",
    "# A = 354900\n",
    "# B = A+200\n",
    "\n",
    "print(A, B)\n",
    "print(process.convert_seconds_to_datetime(A), process.convert_seconds_to_datetime(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_harp_times, selected_photodiode_data = process.select_from_photodiode_data(OnixAnalogClock, OnixAnalogData, A, B, conversions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting photodiode data into a pd.Series\n",
    "\n",
    "photodiode_stream = pd.Series(data=selected_photodiode_data[:,0], index=selected_harp_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be a funtion \n",
    "t = (selected_harp_times - utils.harp.REFERENCE_EPOCH).total_seconds()\n",
    "\n",
    "photodiode_low_state_times = t[np.where(selected_photodiode_data[:,0]==0)].to_numpy()\n",
    "intervals_between_states = np.diff(photodiode_low_state_times)\n",
    "\n",
    "threshold = intervals_between_states.mean() + 1 * intervals_between_states.std()\n",
    "\n",
    "inds = np.where(intervals_between_states >= threshold)[0] + 1\n",
    "halt_times = photodiode_low_state_times[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_streams['Eye Movements'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_perievent_segment(trace, event_times, range_around_event):\n",
    "    \n",
    "    selected_trace_chunks = []\n",
    "    \n",
    "    for event_time in event_times:\n",
    "        \n",
    "        start = event_time + range_around_event[0]\n",
    "        end = event_time + range_around_event[1]\n",
    "        \n",
    "        selected_trace_chunks.append(trace.loc[start:end])\n",
    "        \n",
    "    return np.array(selected_trace_chunks)\n",
    "\n",
    "def baseline_subtract_trace_on_selected_range(time_array, trace_array, time_range):\n",
    "    inds = np.where(np.logical_and(time_array >= time_range[0], time_array < time_range[1]))\n",
    "    baselines = trace[:, inds].squeeze().mean(axis=1)\n",
    "    baselines = baselines.repeat(trace_array.shape[1]).reshape(trace_array.shape)\n",
    "    return trace_array - baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaged_pupil_diameter_stream = pd.Series(np.mean(np.stack((resampled_streams['Eye Movements']['Ellipse.Width'], resampled_streams['Eye Movements']['Ellipse.Height'])), axis=0), index=resampled_streams['Eye Movements']['Ellipse.Height'].index)\n",
    "averaged_pupil_diameter_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_around_halt = [-5,11]\n",
    "\n",
    "# Selecting perievent segments\n",
    "selected_chunks = {}\n",
    "select_perievent_segment_func = lambda x: select_perievent_segment(process.convert_stream_from_datetime_to_seconds(x), halt_times, range_around_halt)\n",
    "selected_chunks['GRAB df/F'] = select_perievent_segment_func(resampled_streams['Photometry']['470_dfF'])\n",
    "selected_chunks['Running'] = select_perievent_segment_func(running)\n",
    "selected_chunks['Horizontal eye movement'] = select_perievent_segment_func(resampled_streams['Eye Movements']['Ellipse.Center.X'])\n",
    "selected_chunks['Vertical eye movement'] = select_perievent_segment_func(resampled_streams['Eye Movements']['Ellipse.Center.X'])\n",
    "# selected_chunks['Pupil diameter width'] = select_perievent_segment_func(resampled_streams['Eye Movements']['Ellipse.Width'])\n",
    "# selected_chunks['Pupil diameter height'] = select_perievent_segment_func(resampled_streams['Eye Movements']['Ellipse.Height'])\n",
    "selected_chunks['Pupil diameter'] = select_perievent_segment_func(averaged_pupil_diameter_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baselining the selected segments\n",
    "time_range = [-1, 0] # in relation to the event\n",
    "t = np.linspace(range_around_halt[0], range_around_halt[1], selected_chunks['GRAB df/F'].shape[1])\n",
    "\n",
    "for name, trace in selected_chunks.items():\n",
    "    selected_chunks[name] = baseline_subtract_trace_on_selected_range(t, trace, time_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoiding to baseline the Photodiode\n",
    "selected_chunks['Photodiode'] = select_perievent_segment_func(photodiode_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(selected_chunks['GRAB df/F'].shape[0]): plt.plot(np.linspace(range_around_halt[0], range_around_halt[1], selected_chunks['GRAB df/F'].shape[1]), selected_chunks['GRAB df/F'][i,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabels = [\n",
    "    'GRAB df/F (%)',\n",
    "    'speed (cm/s)',\n",
    "    'horizontal coordinga (pixels)',\n",
    "    'vertical coordinate (pixels)',\n",
    "    'pupli diameter (pixels)',\n",
    "    'photodiode state'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=len(selected_chunks), ncols=1, figsize=(12,(len(selected_chunks)-1)*6))\n",
    "\n",
    "for i, (label, trace) in enumerate(selected_chunks.items()):\n",
    "    t = np.linspace(range_around_halt[0], range_around_halt[1], trace.shape[1])\n",
    "    ax_traces = []\n",
    "    for j in range(trace.shape[0]):\n",
    "        ax_traces.append(ax[i].plot(t, trace[j, :], c='black', alpha=0.7))\n",
    "    ax_traces[-1][0].set_label(label) # assign a label to a single trace only\n",
    "    ax[i].add_patch(patches.Rectangle((0, ax[i].get_ylim()[0]), 1, ax[i].get_ylim()[1]-ax[i].get_ylim()[0], edgecolor='none',facecolor='red', alpha=0.3))\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel('time from halt (s)')\n",
    "    ax[i].set_ylabel(ylabels[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aeon]",
   "language": "python",
   "name": "conda-env-aeon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
