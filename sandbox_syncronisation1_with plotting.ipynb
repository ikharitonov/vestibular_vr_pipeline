{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Extract and align data from Onix, Harp, Sleap, and photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import harp\n",
    "import plotly.express as px\n",
    "\n",
    "from harp_resources import process, utils\n",
    "from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort0 = False #only read harp data when it exists, not in Cohort0 \n",
    "cohort2 = False\n",
    "\n",
    "#Cohort 1 single OnixDigital file\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2717-2024-12-12T13-00-21') #single onix_digital files\n",
    "\n",
    "#Cohort 1 multiple OnixDigital files \n",
    "data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2718-2024-12-12T13-28-14') #multiple onix_digital file\n",
    "\n",
    "#Cohort 1 with clock accumulation issue marked on google sheet \n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2719-2024-12-12T13-59-38') #multiple onix_digital file\n",
    "\n",
    "#Cohort 0 (no OnixHarp in this Cohort)\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort0/Cohort0_GCaMP_example/B3M3xx-2024-08-08T10-05-26')\n",
    "#cohort0 = True\n",
    "\n",
    "#Cohort 2 N.B. no videodata or photometry in this test set \n",
    "# cohort2 = True\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_like_test_data/2025-01-13T15-47-26')\n",
    "\n",
    "#Cohort 2 longer test NO OnixHarp! Clock increasing exponentially according to NORA, but does not show uissue N.B. no photometry in this test set (neitjer videos, but yes video_data)\n",
    "#cohort2 = True\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_test_longer/2025-02-07T16-05-04')\n",
    "\n",
    "#Cohort 2 longer test YES OnixHarp! N.B. no photometry in this test set (neitjer videos, but yes video_data)\n",
    "#cohort2 = True\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_test_longer/2025-02-10T08-18-59')\n",
    " \n",
    "\n",
    "photometry_path = data_path.parent / f\"{data_path.name}_processedData\" / \"photometry\"\n",
    "\n",
    "# h1_datafolder = data_path / 'HarpDataH1' #only if reading separate registers\n",
    "# h2_datafolder = data_path / 'HarpDataH2' #only if reading separate registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h1 and h2 only needed if timestamps are readed separately and not as all harp_streams\n",
    "# h1_reader = harp.create_reader('harp_resources/h1-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "# h2_reader = harp.create_reader('harp_resources/h2-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "\n",
    "session_settings_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "onix_framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "#photometry_reader = utils.PhotometryReader(\"Processed_fluorescence\")\n",
    "video_reader1 = utils.Video(\"VideoData1\")\n",
    "video_reader2 = utils.Video(\"VideoData2\")\n",
    "onix_digital_reader = utils.OnixDigitalReader(\"OnixDigital\", columns=[\"Value.Clock\", \"Value.HubClock\", \n",
    "                                                                         \"Value.DigitalInputs\",\n",
    "                                                                         \"Seconds\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read metadata in 2 different ways (to df or to dict, to decide which one is better in the future)\n",
    "print (\"Loading session settings\")\n",
    "session_settings = utils.load_2(session_settings_reader, data_path) #Andrew's, creates ugly df, but used in further analysis code\n",
    "#session_settings = utils.read_SessionSettings(data_path) #Hilde's, creates prety dict, not aware of multiple files\n",
    "\n",
    "# read experiment events, video, processed photometry \n",
    "print (\"Loading experiment events\")\n",
    "experiment_events = utils.load_2(experiment_events_reader, data_path)\n",
    "if not cohort2:\n",
    "    print (\"Loading processed fluorescence\")\n",
    "    photometry_data=pd.read_csv(str(photometry_path)+'/Processed_fluorescence.csv')\n",
    "    print (\"Loading processed fluorescence info\")\n",
    "    photometry_info=pd.read_csv(str(photometry_path)+'/Info.csv')\n",
    "    print (\"Loading processed fluorescence events\")\n",
    "    photometry_events=pd.read_csv(str(photometry_path)+'/Events.csv')\n",
    "    print (\"Loading video data 1\")\n",
    "    video_data1 = utils.load_2(video_reader1, data_path)\n",
    "    print (\"Loading video data 2\")\n",
    "    video_data2 = utils.load_2(video_reader2, data_path)\n",
    "\n",
    "# read Onix data \n",
    "print (\"Loading OnixDigital\")\n",
    "onix_digital = utils.load_2(onix_digital_reader, data_path)\n",
    "print (\"Loading OnixAnalogFrameClock\")\n",
    "onix_analog_framecount = utils.load_2(onix_framecount_reader, data_path)\n",
    "print (\"Loading OnixAnalogClock\")\n",
    "onix_analog_clock = utils.read_OnixAnalogClock(data_path)\n",
    "print (\"Loading OnixAnalogData\")\n",
    "onix_analog_data = utils.read_OnixAnalogData(data_path, channels = [0], binarise=True) #channels is a list of AI lines, 0-11\n",
    "\n",
    "#read harp streams and separate registers if needed \n",
    "print (\"Loading H1 and H2 streams as dict or df\")\n",
    "harp_streams = utils.load_registers(data_path, dataframe = True) #loads as df, or if False, as dict \n",
    "\n",
    "#read syncronising signal between HARP and ONIX\n",
    "if not cohort0:\n",
    "    print (\"Loading OnixHarp\")\n",
    "    onix_harp = utils.load_2(onix_harp_reader, data_path)\n",
    "    # removing possible outliers \n",
    "    onix_harp = utils.detect_and_remove_outliers(\n",
    "    df=onix_harp,\n",
    "    x_column=\"HarpTime\",\n",
    "    y_column=\"Clock\",\n",
    "    verbose=False  # True prints all outliers\n",
    "    )\n",
    "\n",
    "# print (\" \")\n",
    "# print (\"loading separate registers from H1 and H2 data\")\n",
    "# print (\"Loading camera triggers\")\n",
    "# camera_triggers = utils.load_harp(h1_reader.Cam0Event, h1_datafolder) #assumes Cam0 triggers both cameras\n",
    "# print (\"Loading flow sensor data\")\n",
    "# flow_sensor = utils.load_harp(h1_reader.OpticalTrackingRead, h1_datafolder)\n",
    "print (\"Done Loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "plotting onix_analog_clock vs index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# Downsample the data\n",
    "downsample_factor = 100\n",
    "clock_downsampled = onix_analog_clock[::downsample_factor]\n",
    "\n",
    "# Create figure using WebGL rendering\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scattergl(\n",
    "    y=clock_downsampled,\n",
    "    mode=\"lines\",\n",
    "    name=\"Onix Analog Clock\"\n",
    "))\n",
    "\n",
    "# Update layout for performance\n",
    "fig.update_layout(\n",
    "    title=\"Onix Analog Clock Over Time (Optimized)\",\n",
    "    xaxis_title=\"Index (Downsampled)\",\n",
    "    yaxis_title=\"Onix Analog Clock\",\n",
    "    dragmode=\"pan\"\n",
    ")\n",
    "\n",
    "# Show the optimized figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### DEV align Onix, HARP and Photometry data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)  # Forces Python to reload the updated module\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversions = process.photometry_alingment_Cohort1plus(\n",
    "    onix_analog_clock, \n",
    "    onix_analog_framecount,\n",
    "    onix_digital,\n",
    "    photometry_events, \n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def plot_linfit(df, x_column, y_column):\n",
    "    \"\"\"\n",
    "    Plots `Clock` vs `HarpTime` and fits a linear model.\n",
    "    Prints fit parameters (slope, intercept) and evaluation metrics (RMSE, MAE, R-squared).\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        x_column (str): The column name for the independent variable (HarpTime).\n",
    "        y_column (str): The column name for the dependent variable (Clock).\n",
    "    \"\"\"\n",
    "    # Fit linear model\n",
    "    X = df[x_column].values.reshape(-1, 1)\n",
    "    y = df[y_column].values\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Predict values\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Calculate fit parameters and metrics\n",
    "    slope = model.coef_[0]\n",
    "    intercept = model.intercept_\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "\n",
    "    # Print fit parameters and evaluation metrics\n",
    "    print(f\"Fit Parameters:\")\n",
    "    print(f\"  Slope: {slope}\")\n",
    "    print(f\"  Intercept: {intercept}\")\n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    print(f\"  RMSE (in y units): {rmse}\")\n",
    "    print(f\"  MAE: {mae}\")\n",
    "    print(f\"  R-squared: {r2}\")\n",
    "\n",
    "    # Add fitted values to the DataFrame\n",
    "    df[\"Fitted_Y\"] = y_pred\n",
    "\n",
    "    # Plot data with fitted line\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=x_column,\n",
    "        y=y_column,\n",
    "        title=f\"{y_column} vs {x_column} with Linear Fit\",\n",
    "        labels={x_column: x_column, y_column: y_column}\n",
    "    )\n",
    "\n",
    "    # Add fitted line\n",
    "    fig.add_scatter(\n",
    "        x=df[x_column],\n",
    "        y=df[\"Fitted_Y\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Fitted Line\"\n",
    "    )\n",
    "    fig.update_traces(hoverinfo=\"none\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_linfit(onix_harp, \"HarpTime\", \"Clock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def fit_and_plot(df, x_column, y_column, downsample_factor=10):\n",
    "    \"\"\"\n",
    "    Fits a linear model to the full dataset and plots a downsampled scatter plot with the fitted line.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame containing the data.\n",
    "        x_column (str): Column name for the independent variable (X).\n",
    "        y_column (str): Column name for the dependent variable (Y).\n",
    "        downsample_factor (int): Factor for downsampling the data for plotting (default: 10).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Fit parameters including slope, intercept, and R-squared value.\n",
    "    \"\"\"\n",
    "    # Ensure data is in NumPy array format\n",
    "    X_full = df[x_column].to_numpy().reshape(-1, 1)  # Full dataset\n",
    "    y_full = df[y_column].to_numpy().squeeze()  # Ensure 1D array\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_full, y_full)\n",
    "\n",
    "    # Compute fit parameters\n",
    "    slope = model.coef_[0]\n",
    "    intercept = model.intercept_\n",
    "    y_pred_full = model.predict(X_full)\n",
    "    r2 = r2_score(y_full, y_pred_full)\n",
    "\n",
    "    # Print fit parameters\n",
    "    print(f\"Fit Parameters (Full Dataset):\")\n",
    "    print(f\"  Slope: {slope}\")\n",
    "    print(f\"  Intercept: {intercept}\")\n",
    "    print(f\"  R-squared: {r2}\")\n",
    "\n",
    "    # Downsample for efficient plotting\n",
    "    X_downsampled = df[x_column].to_numpy()[::downsample_factor].reshape(-1, 1)\n",
    "    y_downsampled = df[y_column].to_numpy()[::downsample_factor].squeeze()\n",
    "    y_pred_downsampled = model.predict(X_downsampled)  # Predict using full-fit model\n",
    "\n",
    "    # Create Interactive Plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Scatter plot of downsampled data\n",
    "    fig.add_trace(go.Scattergl(\n",
    "        x=X_downsampled.squeeze(),\n",
    "        y=y_downsampled,\n",
    "        mode=\"markers\",\n",
    "        name=\"Downsampled Data\"\n",
    "    ))\n",
    "\n",
    "    # Fitted line (evaluated at downsampled points for smooth rendering)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=X_downsampled.squeeze(),\n",
    "        y=y_pred_downsampled,\n",
    "        mode=\"lines\",\n",
    "        name=\"Fitted Line\",\n",
    "        line=dict(color=\"red\")\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"{y_column} vs {x_column} with Linear Fit\",\n",
    "        xaxis_title=x_column,\n",
    "        yaxis_title=y_column,\n",
    "        dragmode=\"pan\"\n",
    "    )\n",
    "\n",
    "    # Show the optimized figure\n",
    "    fig.show()\n",
    "\n",
    "    # Return fit parameters\n",
    "    return {\"slope\": slope, \"intercept\": intercept, \"r2\": r2}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_results = fit_and_plot(onix_harp, \"HarpTime\", \"Clock\", downsample_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "onix_digital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "onix_harp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def get_memory_usage(var):\n",
    "    size_in_bytes = sys.getsizeof(var)\n",
    "    print(f\"Memory usage: {size_in_bytes / 1024:.2f} KB ({size_in_bytes} bytes)\")\n",
    "\n",
    "get_memory_usage(onix_analog_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK for linearity at loading in utils and report r2 value, only suncronise if r2 > 0.999\n",
    "FIRST decide who gets correlated to who harpvsOnix or the other way around?\n",
    "ALSO consider transforming the datetime index in harp_streams to onix clock upon loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    " data = pd.read_csv('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2718-2024-12-12T13-28-14/OnixHarp/OnixHarp_1904-01-02T00-00-00.csv',\n",
    "                header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "harp_streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "photometry_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "aeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
