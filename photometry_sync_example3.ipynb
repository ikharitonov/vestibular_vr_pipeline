{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is for Cohort 0 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import harp\n",
    "import plotly.express as px\n",
    "import re \n",
    "\n",
    "os.chdir(\"/Users/rancze/Documents/GitHub/vestibular_vr_pipeline/\")\n",
    "print(\"Updated Working Directory:\", os.getcwd())\n",
    "from harp_resources import process, utils\n",
    "\n",
    "# Define paths\n",
    "data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_like_test_data/2025-01-13T15-47-26')\n",
    "photometry_path = data_path.parent / f\"{data_path.name}_processedData\" / \"photometry\"\n",
    "\n",
    "# Load photometry data\n",
    "print(\"Loading processed fluorescence\")\n",
    "photometry_data = pd.read_csv(photometry_path / \"Processed_fluorescence.csv\")\n",
    "\n",
    "print(\"Loading processed fluorescence info\")\n",
    "photometry_info = pd.read_csv(photometry_path / \"Info.csv\")\n",
    "\n",
    "print(\"Loading processed fluorescence events\")\n",
    "photometry_events = pd.read_csv(photometry_path / \"Events.csv\")\n",
    "\n",
    "# Drop NaNs in the \"Name\" column\n",
    "photometry_sync_events = photometry_events.dropna(subset=[\"Name\"]).copy()\n",
    "# Set \"TimeStamp\" as the index\n",
    "photometry_sync_events.set_index(\"TimeStamp\", inplace=True)\n",
    "# Use \"State\" for plotting\n",
    "photometry_sync_events = photometry_sync_events[\"State\"]\n",
    "\n",
    "# Verify extraction\n",
    "print(photometry_sync_events.head())\n",
    "\n",
    "# Only proceed if enough data exists\n",
    "if not photometry_sync_events.empty and len(photometry_sync_events) >= 13:\n",
    "    window = range(0, 13)\n",
    "    plt.figure()\n",
    "    plt.step(photometry_sync_events.index[window], photometry_sync_events.values[window])\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Event State\")\n",
    "    plt.title(\"Photometry Event Synchronization\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Not enough events to plot: found {len(photometry_sync_events)} events.\")\n",
    "\n",
    "# Plot fluorescence data\n",
    "plt.figure()\n",
    "plt.plot(photometry_data[\"dfF_410\"], label=\"CH1-410\")\n",
    "plt.plot(photometry_data[\"dfF_470\"], label=\"CH1-470\")\n",
    "plt.plot(photometry_data[\"dfF_560\"], label=\"CH1-560\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photometry_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import harp\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import cv2\n",
    "import numpy as np\n",
    "import utils\n",
    "import aeon.io.video as video\n",
    "import aeon.analysis.movies as frame_helpers\n",
    "from aeon.io.reader import Reader, Csv\n",
    "from dotmap import DotMap\n",
    "import aeon.io.api as api\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "root_folder = r'/Users/rancze/Documents/Data/vestVR/Cohort2_like_test_data/2025-01-13T15-47-26'\n",
    "root_folder_photometry = root_folder / f\"{root_folder.name}_processedData\" / \"photometry\"\n",
    "\n",
    "#data_folder = '/Users/rancze/Documents/Data/vestVR/Cohort2_like_test_data/2025-01-13T15-47-26'\n",
    "#photometry_path = data_path.parent / f\"{data_path.name}_processedData\" / \"photometry\"\n",
    "\n",
    "h1_reader = harp.create_reader('h1-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "h2_reader = harp.create_reader('h2-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "session_data_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "photometry_reader = utils.PhotometryReader(\"Processed_fluorescence\")\n",
    "video_reader = utils.Video(\"VideoData1\")\n",
    "onix_digital_reader = utils.TimestampedCsvReader(\"OnixDigital\", columns=[\"Clock\", \"HubClock\", \"DigitalInputs\", \"Buttons\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])\n",
    "\n",
    "h1_datafolder = r'/Users/rancze/Documents/Data/vestVR/Cohort2_like_test_data/2025-01-13T15-47-26//HarpDataH1/'\n",
    "h2_datafolder = r'/Users/rancze/Documents/Data/vestVR/Cohort2_like_test_data/2025-01-13T15-47-26//HarpDataH2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read experiment metadata\n",
    "session_settings = utils.load(session_data_reader, root_folder)\n",
    "\n",
    "print(session_settings.iloc[0]['metadata'].blocks[1].haltProtocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read harp streams, experiment events, video\n",
    "flow_sensor = utils.load_harp(h1_reader.OpticalTrackingRead, h1_datafolder)\n",
    "camera_triggers = utils.load_harp(h1_reader.Cam0Event, h1_datafolder)\n",
    "# immediate_pulses = utils.load_harp(h2_reader.ImmediatePulses, h2_datafolder)\n",
    "analog_input = utils.load_harp(h2_reader.AnalogInput, h2_datafolder)\n",
    "experiment_events = utils.load(experiment_events_reader, root_folder)\n",
    "# video_data = utils.load(video_reader, root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experiment_events)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(flow_sensor['OpticalTrackingRead0Y'])\n",
    "plt.plot(analog_input['AnalogInput'])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(experiment_events.index, experiment_events[\"Event\"], c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read onix streams\n",
    "# stream assigns a harp timestamp to each analog block\n",
    "analog_frame_count = utils.load(framecount_reader, root_folder)\n",
    "\n",
    "# load onix digital data\n",
    "digital_data = utils.load(onix_digital_reader, root_folder)\n",
    "\n",
    "# load harp timestamps\n",
    "onix_harp = utils.load(onix_harp_reader, root_folder)\n",
    "onix_harp[\"HarpTime\"] = onix_harp[\"HarpTime\"] + 1 # known issue with current version of ONIX, harp timestamps lag 1 second\n",
    "\n",
    "# directly read an onix analog data / clock bin file\n",
    "analog_data = utils.read_onix_analog_data(root_folder, \"OnixAnalogData\", np.int16)\n",
    "analog_clock = utils.read_onix_analog_clock(root_folder, \"OnixAnalogClock\", np.uint64)\n",
    "\n",
    "# confirm relationship between data, clock and frame count\n",
    "print(analog_data.shape[0], analog_clock.shape[0], analog_frame_count[\"Index\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define conversion functions between timestamps (onix to harp)\n",
    "clock = onix_harp[\"Clock\"] # ONIX hardware clock\n",
    "harp = onix_harp[\"HarpTime\"] # corresponding harp time\n",
    "\n",
    "o_m, o_b = np.polyfit(clock, harp, 1)\n",
    "onix_to_harp_seconds = lambda x: x*o_m + o_b\n",
    "onix_to_harp_timestamp = lambda x: api.aeon(onix_to_harp_seconds(x))\n",
    "harp_to_onix_clock = lambda x: (x - o_b) / o_m\n",
    "\n",
    "window = range(0, 10)\n",
    "plt.figure()\n",
    "plt.scatter(clock[window], harp[window], c='k', s=2)\n",
    "plt.plot(clock[window], onix_to_harp_seconds(clock[window]), c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read photometry stream\n",
    "import  utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "#importlib.reload(process) # Forces Python to reload the updated module\n",
    "None\n",
    "photometry = utils.load_photometry(photometry_reader, root_folder_photometry)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(photometry[0][\"CH1-410\"])\n",
    "plt.plot(photometry[0][\"CH1-470\"])\n",
    "plt.plot(photometry[0][\"CH1-560\"])\n",
    "\n",
    "print (\"Loading processed fluorescence\")\n",
    "photometry_data=pd.read_csv(str(root_folder_photometry)+'/Processed_fluorescence.csv')\n",
    "print (\"Loading processed fluorescence info\")\n",
    "photometry_info=pd.read_csv(str(root_folder_photometry)+'/Info.csv')\n",
    "print (\"Loading processed fluorescence events\")\n",
    "photometry_events=pd.read_csv(str(root_folder_photometry)+'/Events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# photometry sync example\n",
    "# binarise photometry input events\n",
    "photometry_sync_events = photometry[0][\"Events\"]\n",
    "photometry_sync_events = photometry_sync_events[~photometry_sync_events.isna()] # Restrict to events\n",
    "photometry_sync_events = photometry_sync_events.transform(lambda x: int(x.split('*')[2])) # Extract channel value\n",
    "\n",
    "# extract corresponding events in onix\n",
    "digital_data[\"_sync_line\"] = 1 - digital_data[\"DigitalInputs\"] & 1\n",
    "\n",
    "window = range(0, 13)\n",
    "plt.figure()\n",
    "plt.step(photometry_sync_events.index[window], photometry_sync_events.values[window])\n",
    "\n",
    "plt.figure()\n",
    "plt.step(digital_data.iloc[window][\"Clock\"], digital_data.iloc[window][\"_sync_line\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(photometry_sync_events.index, digital_data[\"Clock\"])\n",
    "\n",
    "# define conversion functions between timestamps (onix to harp)\n",
    "m, b = np.polyfit(photometry_sync_events.index, digital_data[\"Clock\"], 1)\n",
    "photometry_to_onix_time = lambda x: x*m + b\n",
    "photometry_to_harp_time = lambda x: onix_to_harp_timestamp(photometry_to_onix_time(x))\n",
    "onix_time_to_photometry = lambda x: (x - b) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example, see harp data, experiment events, onix data for a given window, synchronised.\n",
    "# where did the LinearRegularMismatch block start (approximately)?\n",
    "block_start = experiment_events[experiment_events[\"Event\"].eq(\"DrumBase block started\")]\n",
    "print(block_start)\n",
    "\n",
    "# Get the first 20 halt times after this block started\n",
    "block_halts = experiment_events[(experiment_events[\"Event\"].eq(\"Apply halt: 1s\")) & (experiment_events.index > block_start.index[0])].iloc[0:20]\n",
    "\n",
    "# Plot flow sensor and camera triggers during given halt period\n",
    "idx = 0\n",
    "sec_start = block_halts.index[idx]\n",
    "sec_stop = block_halts.index[idx+1]\n",
    "min_time = sec_start - pd.DateOffset(seconds=1)\n",
    "max_time = sec_stop + pd.DateOffset(seconds=0.5)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(flow_sensor['OpticalTrackingRead0X'][min_time:max_time], label='Flow X')\n",
    "plt.plot(flow_sensor['OpticalTrackingRead0Y'][min_time:max_time], label='Flow Y')\n",
    "plt.scatter(camera_triggers[min_time:max_time].index, np.ones((1, len(camera_triggers[min_time:max_time]))) * -10, s=1, c='k', label='Camera Trigger')\n",
    "plt.axvspan(sec_start, sec_start + pd.DateOffset(seconds=0.1), color='black', alpha=0.2, label='Halt Command')\n",
    "\n",
    "# overlay the onix photodiode signal in converted time\n",
    "onix_sec_start_time = harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] - 1)\n",
    "onix_sec_start_index = np.where(analog_clock >= onix_sec_start_time)[0][0]\n",
    "\n",
    "onix_sec_stop_time = harp_to_onix_clock(block_halts.iloc[idx+1][\"Seconds\"])\n",
    "onix_sec_stop_index = np.where(analog_clock >= onix_sec_stop_time)[0][0]\n",
    "plt.plot(onix_to_harp_timestamp(analog_clock[onix_sec_start_index:onix_sec_stop_index]), analog_data[onix_sec_start_index:onix_sec_stop_index, 0], label='Photodiode')\n",
    "\n",
    "# overlay photometry\n",
    "photometry_sec_start_time = onix_time_to_photometry(onix_sec_start_time)\n",
    "photometry_sec_stop_time = onix_time_to_photometry(onix_sec_stop_time)\n",
    "photometry_sec = photometry[0].loc[(photometry[0].index >= photometry_sec_start_time) & (photometry[0].index <= photometry_sec_stop_time)]\n",
    "\n",
    "plt.plot(photometry_to_harp_time(photometry_sec.index), photometry_sec['CH1-410'], label='CH1-410')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aeon]",
   "language": "python",
   "name": "conda-env-aeon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
