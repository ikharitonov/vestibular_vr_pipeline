{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from harp_resources import process, utils\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/home/ikharitonov/RANCZLAB-NAS/data/ONIX/20240730_Mismatch_Experiment/GRAB_MMclosed&Regular_220824/2024-08-22T13-13-15_B3M6')\n",
    "photometry_path = Path('/home/ikharitonov/RANCZLAB-NAS/data/ONIX/20240730_Mismatch_Experiment/GRAB_MMclosed&Regular_220824/photometry/B3M6_MMclosed&Regular_day1/2024_08_22-15_16_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_smoothing(X,k):\n",
    "    S = np.zeros(X.shape[0])\n",
    "    for t in range(X.shape[0]):\n",
    "        if t < k:\n",
    "            S[t] = np.mean(X[:t+1])\n",
    "        else:\n",
    "            S[t] = np.sum(X[t-k:t])/k\n",
    "    return S\n",
    "\n",
    "def running_unit_conversion(running_array):\n",
    "    resolution = 12000 # counts per inch\n",
    "    inches_per_count = 1 / resolution\n",
    "    meters_per_count = 0.0254 * inches_per_count\n",
    "    dt = 0.01 # for OpticalTrackingRead0Y(46)\n",
    "    linear_velocity = meters_per_count / dt # meters per second per count\n",
    "    \n",
    "    # ball_radius = 0.1 # meters \n",
    "    # angular_velocity = linear_velocity / ball_radius # radians per second per count\n",
    "    # angular_velocity = angular_velocity * (180 / np.pi) # degrees per second per count\n",
    "    # print(angular_velocity)\n",
    "    \n",
    "    return running_array * linear_velocity * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_csv = pd.read_csv('/home/ikharitonov/Downloads/preprocessed_grab.csv')\n",
    "preprocessed_csv['TimeStamp'] = preprocessed_csv['TimeStamp'] * 1000\n",
    "preprocessed_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "streams = utils.load_registers(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversions = process.calculate_conversions_second_approach(data_path, photometry_path, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_csv['HARP Timestamps'] = conversions['photometry_to_harp_time'](preprocessed_csv['TimeStamp'])\n",
    "preprocessed_csv['HARP Seconds'] = process.convert_datetime_to_seconds(preprocessed_csv['HARP Timestamps'])\n",
    "preprocessed_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OnixAnalogClock = utils.read_OnixAnalogClock(data_path)\n",
    "OnixAnalogData = utils.read_OnixAnalogData(data_path, binarise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Photodiode start', conversions['onix_to_harp_timestamp'](OnixAnalogClock[0]))\n",
    "print('Photodiode stop', conversions['onix_to_harp_timestamp'](OnixAnalogClock[-1]))\n",
    "print('Photometry start', preprocessed_csv['HARP Timestamps'].iloc[0])\n",
    "print('Photometry stop', preprocessed_csv['HARP Timestamps'].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentEvents = utils.read_ExperimentEvents(data_path)\n",
    "ExperimentEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentEvents.Value.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentEvents[ExperimentEvents.Value=='Apply halt: 1s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentEvents[ExperimentEvents.Value=='LinearMismatch block started']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = ExperimentEvents[ExperimentEvents.Value=='Apply halt: 1s'].iloc[0].Seconds\n",
    "# B = ExperimentEvents[ExperimentEvents.Value=='Apply halt: 1s'].iloc[-1].Seconds\n",
    "\n",
    "# A = ExperimentEvents.iloc[0].Seconds\n",
    "# B = ExperimentEvents.iloc[-1].Seconds\n",
    "\n",
    "A = ExperimentEvents[ExperimentEvents.Value=='LinearMismatch block started'].iloc[0].Seconds\n",
    "B = ExperimentEvents.iloc[-1].Seconds\n",
    "\n",
    "# A = 354900\n",
    "# B = A+200\n",
    "\n",
    "print(A, B)\n",
    "print(process.convert_seconds_to_datetime(A), process.convert_seconds_to_datetime(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_harp_times, selected_photodiode_data = process.select_from_photodiode_data(OnixAnalogClock, OnixAnalogData, A, B, conversions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(12,12))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(preprocessed_csv[preprocessed_csv['HARP Seconds'].between(A, B)]['HARP Seconds'], preprocessed_csv[preprocessed_csv['HARP Seconds'].between(A, B)]['470_dfF'], label='470nm')\n",
    "\n",
    "t = (selected_harp_times - utils.harp.REFERENCE_EPOCH).total_seconds()\n",
    "plt.plot(t, selected_photodiode_data[:,0], label='Photodiode')\n",
    "plt.xlabel('HARP Seconds')\n",
    "plt.ylabel('df/F (%)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "# running in cm/s\n",
    "y1 = streams['H1']['OpticalTrackingRead0X(46)'].loc[process.convert_seconds_to_datetime(A):process.convert_seconds_to_datetime(B)]\n",
    "y1 = running_unit_conversion(y1)\n",
    "t = (y1.index - utils.harp.REFERENCE_EPOCH).total_seconds()\n",
    "# y2 = savgol_filter(y1, 50, 3)\n",
    "y3 = moving_average_smoothing(y1, 50)\n",
    "# plt.plot(t, y1, label='Raw running')\n",
    "# plt.plot(t, y2, label='Savgol')\n",
    "plt.plot(t, y3, label='Moving average')\n",
    "plt.legend()\n",
    "plt.xlabel('HARP Seconds')\n",
    "plt.ylabel('running (cm/s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## halt time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (selected_harp_times - utils.harp.REFERENCE_EPOCH).total_seconds()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "photodiode_low_state_times = t[np.where(selected_photodiode_data[:,0]==0)].to_numpy()\n",
    "intervals_between_states = np.diff(photodiode_low_state_times)\n",
    "print(photodiode_low_state_times)\n",
    "print(intervals_between_states)\n",
    "print(photodiode_low_state_times.shape, intervals_between_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking what are the differences between the time values that we selected are (those corresponding to low states of photodiode)\n",
    "counts, intervals, _ = plt.hist(intervals_between_states, bins=100)\n",
    "print(counts)\n",
    "print(intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# low many values there are in the smallest interval\n",
    "counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of differences plus two standard deviations\n",
    "threshold = intervals_between_states.mean() + 1 * intervals_between_states.std()\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_between_states[np.where(intervals_between_states < threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The number of values in the first interval [{intervals[0]}, {intervals[1]}] = {counts[0]} == the number of difference values between halt occurrences < chosen threshold {threshold} = {intervals_between_states[np.where(intervals_between_states < threshold)].shape[0]} ==> {counts[0]==intervals_between_states[np.where(intervals_between_states < threshold)].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_between_states[np.where(intervals_between_states >= threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the indices where there are large time gaps between low states of photodiode (which are disconnected - distinct halts)\n",
    "inds = np.where(intervals_between_states >= threshold)[0] + 1\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the HARP second values for these halt beginning events\n",
    "halt_times = photodiode_low_state_times[inds]\n",
    "halt_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a visual check the detected halt time correspond to the photodiode trace\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(preprocessed_csv[preprocessed_csv['HARP Seconds'].between(A, B)]['HARP Seconds'], preprocessed_csv[preprocessed_csv['HARP Seconds'].between(A, B)]['470_dfF'])\n",
    "\n",
    "t = (selected_harp_times - utils.harp.REFERENCE_EPOCH).total_seconds()\n",
    "plt.plot(t, selected_photodiode_data[:,0])\n",
    "\n",
    "for halt_time in halt_times:\n",
    "    plt.axvline(halt_time, c='r', alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## block average F0 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_segment(trace, time_column_name, start, end):\n",
    "    return trace[trace[time_column_name].between(start, end)]\n",
    "\n",
    "def get_perievent_trace(trace, time_column_name, event_time, before_event_period=5, during_event_period=1, after_event_period=5):\n",
    "    pre_event_time = event_time - before_event_period\n",
    "    after_event_time = event_time + during_event_period + after_event_period\n",
    "    return select_segment(trace, time_column_name, pre_event_time, after_event_time)\n",
    "\n",
    "def dfF(trace, F0):\n",
    "    return (trace - F0) / F0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentEvents.Value.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = ExperimentEvents[ExperimentEvents.Value.isin(['LinearNormal block started', 'LinearRegularMismatch block started', 'LinearMismatch block started'])]\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "block1_start = preprocessed_csv['HARP Seconds'].iloc[0]\n",
    "block2_start = temp_df.iloc[1]['Seconds']\n",
    "block3_start = temp_df.iloc[2]['Seconds']\n",
    "block3_end = preprocessed_csv['HARP Seconds'].iloc[-1]\n",
    "\n",
    "print(block1_start, block2_start, block3_start, block3_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = preprocessed_csv[['HARP Seconds','470_dfF']]\n",
    "block1_average_dfF = select_segment(temp_data, 'HARP Seconds', block1_start, block2_start)['470_dfF'].mean()\n",
    "block1_std_dfF = select_segment(temp_data, 'HARP Seconds', block1_start, block2_start)['470_dfF'].std()\n",
    "block2_average_dfF = select_segment(temp_data, 'HARP Seconds', block2_start, block3_start)['470_dfF'].mean()\n",
    "block2_std_dfF = select_segment(temp_data, 'HARP Seconds', block2_start, block3_start)['470_dfF'].std()\n",
    "block3_average_dfF = select_segment(temp_data, 'HARP Seconds', block3_start, block3_end)['470_dfF'].mean()\n",
    "block3_std_dfF = select_segment(temp_data, 'HARP Seconds', block3_start, block3_end)['470_dfF'].std()\n",
    "\n",
    "print('block1 mean', block1_average_dfF, 'std', block1_std_dfF)\n",
    "print('block2 mean', block2_average_dfF, 'std', block2_std_dfF)\n",
    "print('block3 mean', block3_average_dfF, 'std', block3_std_dfF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "\n",
    "plt.scatter(0,block1_average_dfF, c='black')\n",
    "# plt.errorbar(0, block1_average_dfF, yerr=block1_std_dfF, capsize=5, c='black')\n",
    "\n",
    "plt.scatter(1,block2_average_dfF, c='black')\n",
    "# plt.errorbar(1, block2_average_dfF, yerr=block2_std_dfF, capsize=5, c='black')\n",
    "\n",
    "plt.scatter(2,block3_average_dfF, c='black')\n",
    "# plt.errorbar(2, block3_average_dfF, yerr=block3_std_dfF, capsize=5, c='black')\n",
    "\n",
    "plt.xticks([0,1,2], ['Baseline', 'Regular mismatches', 'Random mismatches'])\n",
    "plt.ylabel('average df/F (%)')\n",
    "\n",
    "plt.ylim([-0.2, 0.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## perievent analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = preprocessed_csv[preprocessed_csv['HARP Seconds'].between(A, B)][['HARP Seconds','470_dfF']]\n",
    "get_perievent_trace(temp_data, 'HARP Seconds', halt_times[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_unit_conversion(streams['H1']['OpticalTrackingRead0X(46)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average_smoothing(running_unit_conversion(streams['H1']['OpticalTrackingRead0X(46)']), 100).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_unit_conversion(streams['H1']['OpticalTrackingRead0X(46)']).rolling(5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_running = moving_average_smoothing(running_unit_conversion(streams['H1']['OpticalTrackingRead0X(46)']), 100)\n",
    "# all_running = running_unit_conversion(streams['H1']['OpticalTrackingRead0X(46)']).apply(lambda x: moving_average_smoothing(x, 100))\n",
    "all_running = running_unit_conversion(streams['H1']['OpticalTrackingRead0X(46)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_event_period=5\n",
    "during_event_period=1\n",
    "after_event_period=5\n",
    "\n",
    "photometry_chunks = []\n",
    "running_chunks = []\n",
    "\n",
    "for halt_time in halt_times:\n",
    "    \n",
    "    # Select chunk\n",
    "    photometry_chunk = get_perievent_trace(temp_data, 'HARP Seconds', halt_time)\n",
    "    start = process.convert_seconds_to_datetime(halt_time - before_event_period)\n",
    "    end = process.convert_seconds_to_datetime(halt_time + during_event_period + after_event_period)\n",
    "    running_chunk = all_running.loc[start:end]\n",
    "    running_times = (running_chunk.index - utils.harp.REFERENCE_EPOCH).total_seconds()\n",
    "    \n",
    "    start = halt_time - before_event_period\n",
    "#     start = halt_time - 1\n",
    "    end = halt_time\n",
    "    photometry_F0 = select_segment(photometry_chunk, 'HARP Seconds', start, end)['470_dfF'].mean()\n",
    "    running_F0 = running_chunk.loc[process.convert_seconds_to_datetime(start):process.convert_seconds_to_datetime(end)].mean()\n",
    "    \n",
    "    photometry_chunk = dfF(photometry_chunk, photometry_F0)\n",
    "    running_chunk = dfF(running_chunk, running_F0)\n",
    "    \n",
    "    photometry_chunks.append(photometry_chunk['470_dfF'].values)\n",
    "    running_chunks.append(running_chunk.values)\n",
    "\n",
    "photometry_chunks = np.array(photometry_chunks)\n",
    "running_chunks = np.array(running_chunks)\n",
    "print(photometry_chunks.shape, running_chunks.shape)\n",
    "\n",
    "average_photometry_chunk = photometry_chunks.mean(axis=0)\n",
    "average_running_chunk = running_chunks.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "photometry_t = np.linspace(-before_event_period, during_event_period + after_event_period, average_photometry_chunk.shape[0])\n",
    "running_t = np.linspace(-before_event_period, during_event_period + after_event_period, average_running_chunk.shape[0])\n",
    "\n",
    "plt.plot(photometry_t, average_photometry_chunk, label='GRAB df/F (%)')\n",
    "plt.plot(running_t, average_running_chunk, c='black', label='running')\n",
    "# plt.axvline(0, c='r', alpha=0.5)\n",
    "\n",
    "plt.gca().add_patch(patches.Rectangle((0, plt.gca().get_ylim()[0]), 1, plt.gca().get_ylim()[1]-plt.gca().get_ylim()[0], edgecolor='none',facecolor='red', alpha=0.5))\n",
    "\n",
    "plt.xlabel('time from halt (s)')\n",
    "plt.ylabel('relative change (%)')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aeon]",
   "language": "python",
   "name": "conda-env-aeon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
