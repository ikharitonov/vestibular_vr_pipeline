{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from harp_resources import process, utils\n",
    "from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/Users/rancze/Documents/Data/Mismatch_experiments/Cohort0_GCaMP_example/2024-08-08T10-05-26_B3M3')\n",
    "photometry_path = Path('/Users/rancze/Documents/Data/Mismatch_experiments/Cohort0_GCaMP_example/photometry/B3M3_MMclosedOpen_day2/2024_08_08-12_08_29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SessionSettings = utils.read_SessionSettings(data_path, print_contents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Videography and SLEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lp.create_flipped_videos(data_path, what_to_flip='VideoData1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Run SLEAP inference now\n",
    "\n",
    "```\n",
    "In the terminal:\n",
    ">> conda activate sleap\n",
    ">> sleap-label\n",
    "\n",
    "Open \"working_project.slp\" in \"SLEAP_models\" directory on the NAS.\n",
    "SLEAP documentation: https://sleap.ai/tutorials/tutorial.html\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Load videography data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoData1, VideoData2, VideoData1_Has_Sleap, VideoData2_Has_Sleap = lp.load_videography_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### SLEAP Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "VideoData2[VideoData2[columns_of_interest].isnull().all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoData2[VideoData2[columns_of_interest].isnull().all(1)].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nan_df = VideoData2[VideoData2[columns_of_interest].isnull().all(1)]\n",
    "all_nan_index_array = all_nan_df.index.values\n",
    "\n",
    "i=1\n",
    "for group in lp.find_sequential_groups(all_nan_index_array):\n",
    "    print(f'NaN frame group {i} with {len(group)} elements')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in columns_of_interest:\n",
    "# indices_outside_common_nan_list\n",
    "# VideoData2[VideoData2[col].isna()].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "coordinates_dict=lp.get_coordinates_dict(VideoData2, columns_of_interest)\n",
    "\n",
    "for col in columns_of_interest:\n",
    "    plt.figure(figsize=(18,4))\n",
    "    plt.title(col, fontsize=16)\n",
    "    plt.plot(VideoData2[col].values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['left', 'right', 'center', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=11, ncols=1, figsize=(4,44))\n",
    "\n",
    "for col in columns_of_interest:\n",
    "    ax[columns_of_interest.index(col)].set_title(col)\n",
    "    ax[columns_of_interest.index(col)].scatter(coordinates_dict[f'{col}.x'], coordinates_dict[f'{col}.y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### SLEAP processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoData2 = VideoData2.interpolate()\n",
    "\n",
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "coordinates_dict=lp.get_coordinates_dict(VideoData2, columns_of_interest)\n",
    "\n",
    "theta = lp.find_horizontal_axis_angle(VideoData2, 'left', 'center')\n",
    "center_point = lp.get_left_right_center_point(coordinates_dict)\n",
    "\n",
    "columns_of_interest = ['left', 'right', 'center', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "remformatted_coordinates_dict = lp.get_reformatted_coordinates_dict(coordinates_dict, columns_of_interest)\n",
    "centered_coordinates_dict = lp.get_centered_coordinates_dict(remformatted_coordinates_dict, center_point)\n",
    "rotated_coordinates_dict = lp.get_rotated_coordinates_dict(centered_coordinates_dict, theta)\n",
    "\n",
    "columns_of_interest = ['p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "ellipse_parameters_data, ellipse_center_points_data = lp.get_fitted_ellipse_parameters(rotated_coordinates_dict, columns_of_interest)\n",
    "\n",
    "average_diameter = np.mean([ellipse_parameters_data[:,0], ellipse_parameters_data[:,1]], axis=0)\n",
    "\n",
    "SleapVideoData2 = process.convert_arrays_to_dataframe(['Seconds', 'Ellipse.Diameter', 'Ellipse.Angle', 'Ellipse.Center.X', 'Ellipse.Center.Y'], [VideoData2['Seconds'].values, average_diameter, ellipse_parameters_data[:,2], ellipse_center_points_data[:,0], ellipse_center_points_data[:,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Loading and Synchronisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversions = process.calculate_conversions_second_approach(data_path, photometry_path, verbose=False)\n",
    "# After hardware ONIX clock implementation - this will have to be adapted\n",
    "# Only photometry will need to be converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "streams = utils.load_registers(data_path)\n",
    "\n",
    "Photometry = utils.read_fluorescence(photometry_path)\n",
    "Photometry['HARP Timestamps'] = conversions['photometry_to_harp_time'](Photometry['TimeStamp'])\n",
    "\n",
    "OnixAnalogClock = utils.read_OnixAnalogClock(data_path)\n",
    "OnixAnalogData = utils.read_OnixAnalogData(data_path, binarise=True)\n",
    "ExperimentEvents = utils.read_ExperimentEvents(data_path) \n",
    "\n",
    "photodiode_series = pd.Series(OnixAnalogData[:,0], index=conversions['onix_to_harp_timestamp'](OnixAnalogClock))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Photometry, Eye Movements and Photodiode to the streams\n",
    "streams = process.reformat_and_add_many_streams(streams, Photometry, 'Photometry', ['CH1-410', 'CH1-470', 'CH1-560'], index_column_name='HARP Timestamps')\n",
    "#streams = process.reformat_and_add_many_streams(streams, SleapVideoData2, 'SleapVideoData2', ['Ellipse.Diameter', 'Ellipse.Angle', 'Ellipse.Center.X', 'Ellipse.Center.Y'])\n",
    "streams = process.add_stream(streams, 'ONIX', photodiode_series, 'Photodiode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is very memory hungry and kills the kernel even with 20ms resampling period (even though the initial value in the notebook was 0.1ms)\n",
    "#on Ede's mac, it works with down to 25ms but takes a very long time \n",
    "#need to look into pad_and_resample, seems to be using U64 for example \n",
    "#also, there is a lot of data left in the memory after this step, is this necess\n",
    "_ = process.get_timepoint_info(streams, print_all=True)\n",
    "resampled_streams = process.pad_and_resample(streams, resampling_period='25ms', method='linear')\n",
    "_ = process.get_timepoint_info(resampled_streams, print_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying linear and angular conversion to Optical tracking sensor streams\n",
    "# OpticalTrackingRead0X(46) converted to centimeters per second\n",
    "# OpticalTrackingRead0Y(46) covnerted to degrees per second\n",
    "resampled_streams['H1']['OpticalTrackingRead0X(46)'] = process.running_unit_conversion(resampled_streams['H1']['OpticalTrackingRead0X(46)']*100)\n",
    "resampled_streams['H1']['OpticalTrackingRead0Y(46)'] = process.rotation_unit_conversion(resampled_streams['H1']['OpticalTrackingRead0Y(46)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "running = resampled_streams['H1']['OpticalTrackingRead0X(46)']\n",
    "rotation = resampled_streams['H1']['OpticalTrackingRead0Y(46)']\n",
    "photometry = resampled_streams['Photometry']['CH1-470']\n",
    "# eye_movements = resampled_streams['SleapVideoData2']['Ellipse.Center.X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (running.index - utils.harp.REFERENCE_EPOCH).total_seconds() #date stamp to seconds \n",
    "\n",
    "A = t[0] #time window beginning in harp seconds, min different from dataset to dataset, None means from start\n",
    "B = t[-1] #time window end in harp seconds, None means to end \n",
    "# A = 444100 \n",
    "# B = A + 50\n",
    "\n",
    "photodiode_x, photodiode_y = process.select_from_photodiode_data(OnixAnalogClock, OnixAnalogData, A, B, conversions)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, ncols=1, figsize=(12,24))\n",
    "\n",
    "ax[0].plot(t, running)\n",
    "ax[0].set_title('Running')\n",
    "ax[0].set_xlim([A,B])\n",
    "ax[0].set_xlabel('time (seconds)')\n",
    "ax[0].set_ylabel('running speed (cm/s)')\n",
    "\n",
    "ax[1].plot(t, photometry)\n",
    "ax[1].set_title('CH1-470')\n",
    "ax[1].set_xlim([A,B])\n",
    "ax[1].set_xlabel('time (seconds)')\n",
    "ax[1].set_ylabel('signal magnitude')\n",
    "\n",
    "# ax[2].plot(t, eye_movements)\n",
    "# ax[2].set_title('Eye Movements')\n",
    "# ax[2].set_xlim([A,B])\n",
    "# ax[2].set_xlabel('time (seconds)')\n",
    "# ax[2].set_ylabel('horizontal eye position (pixels)')\n",
    "\n",
    "ax[3].plot(process.convert_datetime_to_seconds(photodiode_x), photodiode_y[:,0])\n",
    "ax[3].set_title('Photodiode')\n",
    "ax[3].set_xlim([A,B])\n",
    "ax[3].set_xlabel('time (seconds)')\n",
    "ax[3].set_ylabel('photodiode signal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_to_save_pattern = {'H1': ['OpticalTrackingRead0X(46)', 'OpticalTrackingRead0Y(46)'], 'H2': ['Encoder(38)'], 'Photometry': ['CH1-410', 'CH1-470', 'CH1-560'], 'SleapVideoData1': ['Ellipse.Diameter', 'Ellipse.Center.X', 'Ellipse.Center.Y'], 'SleapVideoData2': ['Ellipse.Diameter', 'Ellipse.Center.X', 'Ellipse.Center.Y'], 'ONIX': ['Photodiode']}\n",
    "streams_to_save_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "process.save_streams_as_h5(data_path, resampled_streams, streams_to_save_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "aeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
