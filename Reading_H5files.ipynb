{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117d03a-88c0-4801-a040-7182e8a1aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from harp_resources import process, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c5c95-b2cf-42fa-8728-1c541f0bd31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_info = {'B2M1': {'sex': 'M', 'area': 'V2M'},\n",
    "              'B2M4': {'sex': 'M', 'area': 'V2M'},\n",
    "              'B2M5': {'sex': 'M', 'area': 'V2M'},\n",
    "              'B2M6': {'sex': 'M', 'area': 'V2M'},\n",
    "              'B3M1': {'sex': 'M', 'area': 'V2M'},\n",
    "              'B3M2': {'sex': 'M', 'area': 'V2M'},\n",
    "              'B3M3': {'sex': 'F', 'area': 'V1'},\n",
    "              'B3M4': {'sex': 'M', 'area': 'V2M'},\n",
    "              'B3M5': {'sex': 'M', 'area': 'V2M'},\n",
    "              'B3M6': {'sex': 'F', 'area': 'V2M'},\n",
    "              'B3M7': {'sex': 'F', 'area': 'V2M'},\n",
    "              'B3M8': {'sex': 'F', 'area': 'V2M'},\n",
    "             }\n",
    "\n",
    "session_info = {'220824': 'day1',\n",
    "                '230824': 'day2',\n",
    "                '190824': 'day1',\n",
    "                '200824': 'day2',\n",
    "                '120824': 'day1',\n",
    "                '130824': 'day2',\n",
    "                '070824': 'day1',\n",
    "                '080824': 'day2',\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e46054-2501-4ce9-8a5b-1fea3187f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_streams_from_h5s(data_paths):\n",
    "    '''\n",
    "    Takes list of H5 file paths and, loads streams into dictionary, and save to dictionary named by mouse ID\n",
    "    '''\n",
    "    #dict to save streams:\n",
    "    reconstructed_dict = {} \n",
    "    # File path to read the HDF5 file\n",
    "    for input_file in data_paths:\n",
    "        name = input_file.split('/')[-1][-7:-3] # Given that file name is of format: resampled_streams_2024-08-22T13-13-15_B3M6.h5 \n",
    "        \n",
    "        if not os.path.exists(input_file):\n",
    "            print(f'ERROR: {input_file} does not exist.')\n",
    "            return None\n",
    "    \n",
    "        # Open the HDF5 file to read data\n",
    "        with h5py.File(input_file, 'r') as h5file:\n",
    "            print(f'reconstructing streams for mouse {input_file.split('/')[-1][-7:-3]}, from session folder: {input_file.split('/')[-3]}')\n",
    "            # Read the common index (which was saved as Unix timestamps)\n",
    "            common_index = h5file['HARP_timestamps'][:]\n",
    "            \n",
    "            # Convert Unix timestamps back to pandas DatetimeIndex\n",
    "            # common_index = pd.to_datetime(common_index)\n",
    "            \n",
    "            # Initialize the dictionary to reconstruct the data\n",
    "            reconstructed_streams = {}\n",
    "            \n",
    "            # Iterate through the groups (sources) in the file\n",
    "            for source_name in h5file.keys():\n",
    "                if source_name == 'HARP_timestamps':\n",
    "                    # Skip the 'common_index' dataset, it's already loaded\n",
    "                    continue\n",
    "                \n",
    "                # Initialize a sub-dictionary for each source\n",
    "                reconstructed_streams[source_name] = {}\n",
    "                \n",
    "                # Get the group (source) and iterate over its datasets (streams)\n",
    "                source_group = h5file[source_name]\n",
    "                \n",
    "                for stream_name in source_group.keys():\n",
    "                    # Read the stream data\n",
    "                    stream_data = source_group[stream_name][:]\n",
    "                    \n",
    "                    # Reconstruct the original pd.Series with the common index\n",
    "                    reconstructed_streams[source_name][stream_name] = pd.Series(data=stream_data, index=common_index)\n",
    "                \n",
    "        reconstructed_dict[name] = reconstructed_streams\n",
    "        print(f'  --> {input_file.split('/')[-1][-7:-3]} streams reconstructed and added to dictionary \\n')\n",
    "            \n",
    "\n",
    "    return reconstructed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5354c9b-ce18-4f36-9966-679ad1ccb8a9",
   "metadata": {},
   "source": [
    "## Defining paths for grab or G8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f317b58-18f5-47e2-8d21-2a85f73ccda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'grab' #'grab' or 'g8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2bb80-e208-4810-901d-de4f2a687de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/Volumes/RanczLab/20240730_Mismatch_Experiment/GRAB_MMclosed-and-open_190824'\n",
    "h5_paths = []\n",
    "eventpaths = []\n",
    "for dirpath, subdirs, files in os.walk(rootdir):\n",
    "    for x in files:\n",
    "        if '.h5' in x:\n",
    "            eventpaths.append(dirpath)\n",
    "            h5_paths.append(dirpath+'/'+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2986cd-8e4f-4146-8f31-9c5df2b0f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''if sensor == 'grab':\n",
    "    paths = ['/Users/hildeteigen/Downloads/resampled_streams_2024-08-22T13-13-15_B3M6.h5']\n",
    "    eventpaths = ['/Volumes/RanczLab/20240730_Mismatch_Experiment/GRAB_MMclosed-and-Regular_220824/2024-08-22T13-13-15_B3M6'] \n",
    "    \n",
    "if sensor == 'g8':\n",
    "    paths = ['/Users/hildeteigen/Downloads/resampled_streams_2024-08-22T13-13-15_B3M6.h5']\n",
    "    eventpaths = ['/Volumes/RanczLab/20240730_Mismatch_Experiment/GRAB_MMclosed-and-Regular_220824/2024-08-22T13-13-15_B3M6'] '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f059e7-c35e-4c7b-b10b-80fec3b14582",
   "metadata": {},
   "source": [
    "### Loading data streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118c69b-7578-4171-9407-a7f0b87d6514",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_dict_dict = load_streams_from_h5s(h5_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c0e4a-53aa-466b-80cf-6388b179d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_dict_dict['B3M8']['H1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c71ad-6f14-4954-af0a-e3a664324e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for mouse, streamdict in stream_dict_dict.items():\n",
    "    #Getting fluorescence traces\n",
    "    fluorescence = streamdict['Photometry']['470_dfF'] #Using '470_dfF' only\n",
    "\n",
    "    #Getting mouse movement data and converting to cm / second\n",
    "    movementX = process.running_unit_conversion(streamdict['H1']['OpticalTrackingRead0X(46)'])*100\n",
    "    movementY = process.running_unit_conversion(streamdict['H1']['OpticalTrackingRead0Y(46)'])*100\n",
    "\n",
    "    #Getting eye movements and pupil diameter\n",
    "    #eye_center_x = streamdict['SleapVideoData2']['Ellipse.Center.X']\n",
    "    #eye_center_y = streamdict['SleapVideoData2']['Ellipse.Center.Y']\n",
    "    #eye_diameter = streamdict['SleapVideoData2']['Ellipse.Diameter']\n",
    "\n",
    "    #Getting visual stimuli event times\n",
    "    event = streamdict['ONIX']['Photodiode']\n",
    "    \n",
    "    time = movementX.index - movementX.index[0]\n",
    "    \n",
    "    dict = {'470_dfF': fluorescence, 'movementX': movementX, 'movementY': movementY, 'event': event,\n",
    "        'Seconds': time}\n",
    "    #dict = {'470_dfF': fluorescence, 'movementX': movementX, 'movementY': movementY, 'event': event,\n",
    "     #   'TimeStamp': time, 'eye_x': eye_center_x, 'eye_y': eye_center_y, 'pupil_diameter': eye_diameter}\n",
    "\n",
    "    df = pd.DataFrame(dict)\n",
    "\n",
    "    #Reversing, so that a halt appearst when 'event'==True\n",
    "    df['event'] = ~df['event']\n",
    "    \n",
    "    df.reset_index(inplace=False)\n",
    "    \n",
    "    data_dict[mouse] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f5d8f-5d3c-4535-8680-cb3229bba94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['B3M7']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e3cda-f0bc-4162-9c4e-831f0a2dc7e2",
   "metadata": {},
   "source": [
    "### Loading Experiment events and session info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dbd981-0803-44d1-9699-152e8ce90770",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict = {}\n",
    "for eventpath in eventpaths:\n",
    "    ExpEvents = utils.read_ExperimentEvents(Path(eventpath))\n",
    "    ExpEvents.set_index('Seconds', inplace = True)\n",
    "    ExpEvents.index = ExpEvents.index.round(4)\n",
    "    name = eventpath.split('/')[-1][-4:]\n",
    "    ExpEvents['experiment'] = eventpath.split('/')[-2].split('_')[1]\n",
    "    for key, item in session_info.items():\n",
    "        if key in eventpath.split('/')[-2]:\n",
    "            ExpEvents['session']=item\n",
    "    event_dict[name] = ExpEvents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc03e74-91ee-4cc0-b4a3-3413cc623055",
   "metadata": {},
   "source": [
    "### Adding events (and non-events) and session info to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de17f2-4255-40df-854f-4fc135881f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict['B3M6'].loc[event_dict['B3M6'].Value == 'LinearPlaybackMismatch block started']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a39ff5-a80d-4c3e-aba6-08a6d19066e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['B3M6']#.loc[data_dict['B3M8'].index >=93949.2902]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff484c-b9cb-4555-84e8-cb1d67c82f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def add_experiment_events(data_dict, events_dict):\n",
    "    # Iterate over each mouse in the dictionaries\n",
    "    for mouse_key in data_dict:\n",
    "        main_df = data_dict[mouse_key]  # Large DataFrame (main data)\n",
    "        event_df = events_dict[mouse_key]  # Small DataFrame (event data)\n",
    "\n",
    "        # Ensure the index of the event_df is named 'Seconds' and has proper precision\n",
    "        event_df.index.name = 'Seconds'\n",
    "        \n",
    "        # Resolve duplicate index values by keeping the first occurrence or handling them accordingly\n",
    "        event_df = event_df[~event_df.index.duplicated(keep='first')]\n",
    "        \n",
    "        # Ensure the same for the main_df, if there are duplicates\n",
    "        main_df = main_df[~main_df.index.duplicated(keep='first')]\n",
    "        \n",
    "        # Use pd.merge_asof to match the nearest milliseconds from main_df index to event_df index\n",
    "        merged_df = pd.merge_asof(\n",
    "            main_df,\n",
    "            event_df[['Value']],  # Only bring in the 'Value' column\n",
    "            left_index=True,  # main_df has time in its index\n",
    "            right_index=True,  # event_df has time in its index (both in ms)\n",
    "            direction='backward',  # Choose the closest event on or before the timestamp\n",
    "            tolerance=0.005 # Adjust tolerance for closest matching (to milliseconds)\n",
    "        )\n",
    "        \n",
    "        # Add 'ExperimentEvents' column to main_df from merged_df\n",
    "        main_df['ExperimentEvents'] = merged_df['Value']\n",
    "        \n",
    "        # Add metadata from event_df\n",
    "        main_df['Experiment'] = event_df['experiment'].unique()[0]\n",
    "        main_df['Session'] = event_df['session'].unique()[0]\n",
    "        \n",
    "        # Add mouse ID, sex, and brain area\n",
    "        main_df['mouseID'] = mouse_key\n",
    "        main_df['sex'] = mouse_info[mouse_key]['sex']\n",
    "        main_df['area'] = mouse_info[mouse_key]['area']\n",
    "        \n",
    "        # Update the dictionary with the modified DataFrame\n",
    "        data_dict[mouse_key] = main_df\n",
    "        \n",
    "        print(f'Events and experiment info added to {mouse_key}')\n",
    "\n",
    "    return data_dict'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a1aed-51fb-4f48-99e2-89488acc0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_experiment_events(data_dict, events_dict, mouse_info):\n",
    "    # Iterate over each mouse key in the dictionaries\n",
    "    for mouse_key in data_dict:\n",
    "        # Retrieve the main and event DataFrames\n",
    "        main_df = data_dict[mouse_key]\n",
    "        event_df = events_dict[mouse_key]\n",
    "\n",
    "        # Resolve duplicate index values by keeping the first occurrence or handling them accordingly\n",
    "        #event_df = event_df[~event_df.index.duplicated(keep='first')]\n",
    "\n",
    "        # Perform a merge_asof on the index to add 'Value' as 'ExperimentEvents' with backward matching\n",
    "        main_df = pd.merge_asof(\n",
    "            main_df.sort_index(),\n",
    "            event_df[['Value']],  # Only select the 'Value' column from event_df\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            direction='backward',\n",
    "            tolerance=0  # Adjust tolerance for matching on the index\n",
    "        )\n",
    "\n",
    "        # Rename the 'Value' column to 'ExperimentEvents'\n",
    "        main_df = main_df.rename(columns={'Value': 'ExperimentEvents'})\n",
    "        \n",
    "        # Add metadata from event_df\n",
    "        main_df['Experiment'] = event_df['experiment'].unique()[0]\n",
    "        main_df['Session'] = event_df['session'].unique()[0]\n",
    "        \n",
    "        # Add mouse ID, sex, and brain area\n",
    "        main_df['mouseID'] = mouse_key\n",
    "        main_df['sex'] = mouse_info[mouse_key]['sex']\n",
    "        main_df['area'] = mouse_info[mouse_key]['area']\n",
    "        \n",
    "        data_dict[mouse_key] = main_df\n",
    "\n",
    "        print(f'Added ExperimentEvents to {mouse_key}')\n",
    "\n",
    "    return data_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c357484-48cc-4a19-9006-244a395efe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = add_experiment_events(data_dict, event_dict,mouse_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f17b943-2b93-411a-aacd-cd47217ca8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['B3M6'].loc[data_dict['B3M6'].ExperimentEvents == 'Block timer elapsed']\n",
    "#data_dict['B3M6'].ExperimentEvents.unique()\n",
    "data_dict['B3M6'].loc[data_dict['B3M6'].index == 98993.4863]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f43c89b-ecf3-4b45-9138-876ac458df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_no_halt_column(data_dict, events_dict):\n",
    "    # Iterate over each mouse in the dictionaries\n",
    "    for mouse_key in data_dict:\n",
    "        main_df = data_dict[mouse_key]  # Large DataFrame\n",
    "        event_df = events_dict[mouse_key]  # Small DataFrame\n",
    "\n",
    "        # Ensure the index of the event_df is named 'Seconds' and is numeric (milliseconds)\n",
    "        event_df.index.name = 'Seconds'\n",
    "\n",
    "        # Create a new column 'No_halt' in the main_df\n",
    "        main_df['No_halt'] = False\n",
    "\n",
    "        # Filter the 'No halt' events from event_df\n",
    "        no_halt_events = event_df[event_df['Value'] == 'No halt']\n",
    "\n",
    "        # Use pd.merge_asof to match the nearest milliseconds from main_df index to event_df index\n",
    "        merged_df = pd.merge_asof(\n",
    "            main_df,\n",
    "            no_halt_events[['Value']],  # Only bring in the 'Value' column where 'No halt' appears\n",
    "            left_index=True,  # main_df has time in its index\n",
    "            right_index=True,  # no_halt_events has time in its index (both in ms)\n",
    "            direction='backward',  # Choose closest event on or before the timestamp\n",
    "            tolerance=0.00005  # Because the dfs generally match down to 4 decimals, and we only want one no_halt at a time\n",
    "        )\n",
    "\n",
    "        # Assign True to the 'No_halt' column where 'No halt' matches\n",
    "        main_df['No_halt'] = merged_df['Value'].fillna(False) == 'No halt'\n",
    "\n",
    "        # Update the dictionary with the modified DataFrame\n",
    "        data_dict[mouse_key] = main_df\n",
    "\n",
    "        print('No_halt events added to', mouse_key)\n",
    "\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac4548c-4e63-46a9-9844-5f376fca6c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = add_no_halt_column(data_dict, event_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b20f5-5199-4ebf-b2c9-7fe7a3647941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that number of no halts matches\n",
    "def no_halt_len(mouse):\n",
    "\n",
    "    event_len = len(event_dict[mouse].loc[event_dict[mouse].Value == 'No halt'])\n",
    "    data_len = len(data_dict[mouse].loc[data_dict[mouse].No_halt == True])\n",
    "    if event_len != data_len:\n",
    "        print(f'for {mouse} the number of actual no-halt events is {event_len} and the number of True values in the data now is {data_len}')\n",
    "        \n",
    "    if event_len == data_len:\n",
    "        print(f'Correct number of no-halt events for {mouse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3133dd05-8634-4c83-83a2-b881463e5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse in data_dict:\n",
    "    no_halt_len(mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d9111-c9a4-4ac7-95cc-3df76cced038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_block_columns(df, event_df):\n",
    "    # Iterate through each index and event value in event_df\n",
    "    prev_column = None  # Tracks the column currently being filled as True\n",
    "    for idx, event in event_df['Value'].items():\n",
    "        if 'block started' in event:\n",
    "            # Create a new column in df, filling with False initially\n",
    "            column_name = event\n",
    "            df[column_name] = False\n",
    "\n",
    "            # If there was a previous column being filled as True, set it to False up to this point\n",
    "            if prev_column is not None:\n",
    "                df.loc[:idx, prev_column] = False\n",
    "\n",
    "            # Set the new column to True starting from this index\n",
    "            df.loc[idx:, column_name] = True\n",
    "            print(df.loc[idx:, column_name])\n",
    "            prev_column = column_name  # Track the events\n",
    "\n",
    "        elif 'Block timer elapsed' in event:\n",
    "    \n",
    "            # If there's a current active block, set its values to False up to this point\n",
    "            if prev_column is not None:\n",
    "                df.loc[idx:, prev_column] = False\n",
    "\n",
    "                prev_column = None  # Reset current column tracker\n",
    "\n",
    "    # Ensure that any remaining True blocks are set to False after their end\n",
    "    #if current_column is not None:\n",
    "     #   df.loc[:, current_column] = False\n",
    "    for col in df:\n",
    "        if 'block started' in col:\n",
    "            df.rename({col: f'{col.split()[0]}_block'}, inplace = True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12ceba-dadd-4f6f-bcfa-5b106a77db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in data_dict.items():\n",
    "    print('updating data for ', name)\n",
    "    blocks_added_df = add_block_columns(df, event_dict[name])\n",
    "    blocks_added_df.replace({})\n",
    "    data_dict[name] = blocks_added_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21ac9e-9f09-4c47-b8b2-6a09c8e33d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['B3M8'].loc[data_dict['B3M8']['LinearMismatch_block']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd676f-b205-44d5-bf31-3bd050630435",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['B3M6'].loc[data_dict['B3M6'].LinearMismatch_block==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cce483-926e-4764-8a9a-b84a4d6619a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['B3M6'].loc[data_dict['B3M6'].No_halt==True]\n",
    "event_dict['B3M6'].loc[event_dict['B3M6'].Value=='LinearPlaybackMismatch block started']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d3988-4457-4be1-a80e-f190ad5e1626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_data(df, time_col='Seconds', interval=0.001):\n",
    "    # Convert the Seconds column to a TimedeltaIndex\n",
    "    df = df.set_index(pd.to_timedelta(df[time_col], unit='s'))\n",
    "\n",
    "    # Define aggregation functions for all possible columns\n",
    "    aggregation_functions = {\n",
    "        '470_dfF': 'mean',\n",
    "        'movementX': 'mean',\n",
    "        'movementY': 'mean',\n",
    "        'event': 'any',\n",
    "        'ExperimentEvents': lambda x: x.dropna().iloc[0] if not x.dropna().empty else None,\n",
    "        'Experiment': 'first',\n",
    "        'Session': 'first',\n",
    "        'mouseID': 'first',\n",
    "        'sex': 'first',\n",
    "        'area': 'first',\n",
    "        'No_halt': 'any',\n",
    "        'LinearMismatch_block': 'any',\n",
    "        'LinearPlaybackMismatch_block': 'any',\n",
    "        'LinearRegular_block': 'any'\n",
    "    }\n",
    "\n",
    "    # Filter aggregation_functions to only include columns present in df\n",
    "    aggregation_functions = {key: func for key, func in aggregation_functions.items() if key in df.columns}\n",
    "\n",
    "    # Resample with the specified interval and apply the filtered aggregations\n",
    "    downsampled_df = df.resample(f'{interval}s').agg(aggregation_functions)\n",
    "\n",
    "    # Reset the index to make the Seconds column normal again\n",
    "    downsampled_df = downsampled_df.reset_index()\n",
    "    downsampled_df[time_col] = downsampled_df[time_col].dt.total_seconds()  # Convert Timedelta back to seconds\n",
    "\n",
    "    # Forward fill for categorical columns if needed, only if they exist in downsampled_df\n",
    "    categorical_cols = ['Experiment', 'Session', 'mouseID', 'sex', 'area']\n",
    "    for col in categorical_cols:\n",
    "        if col in downsampled_df.columns:\n",
    "            downsampled_df[col] = downsampled_df[col].ffill()\n",
    "\n",
    "    # Remove consecutive duplicate values in the 'ExperimentEvents' column, if it exists\n",
    "    if 'ExperimentEvents' in downsampled_df.columns:\n",
    "        downsampled_df['ExperimentEvents'] = downsampled_df['ExperimentEvents'].where(\n",
    "            downsampled_df['ExperimentEvents'] != downsampled_df['ExperimentEvents'].shift()\n",
    "        )\n",
    "\n",
    "    return downsampled_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a63dc6d-5956-44f2-99bd-8f2a6062ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_event_numbers(downsampled_data, original_data, mouse):\n",
    "    nohalt_down = len(downsampled_data.loc[downsampled_data['No_halt']==True])\n",
    "    nohalt_original = len(original_data.loc[original_data['No_halt']==True])\n",
    "    if nohalt_down != nohalt_original:\n",
    "        print(f'mouse{mouse}')\n",
    "        print(f'There are actually {nohalt_original} no-halts, but the downsampled data only contains {nohalt_down}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429171b-e749-4ca6-a84a-9f5fcfea52f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''downsampled_dict = {}\n",
    "for mouse, mouse_df in data_dict.items():\n",
    "    downsampled_df = downsample_data(mouse_df, time_col='Seconds', interval=0.001)\n",
    "    downsampled_dict[mouse]=downsampled_df\n",
    "    test_event_numbers(downsampled_df, mouse_df, mouse)\n",
    "    '''\n",
    "mouse = 'B3M6'\n",
    "downsampled_df = downsample_data(data_dict[mouse], time_col='Seconds', interval=0.001)\n",
    "test_event_numbers(downsampled_df, data_dict[mouse], mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211dd0c1-8344-4a47-93c2-fc1d1afb3952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(downsampled_df['Seconds'].loc[downsampled_df['event']==True], downsampled_df['470_dfF'].loc[downsampled_df['event']==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c4111f-491f-406f-a038-408fe938ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "downsampled_df.ExperimentEvents.unique()#.loc[downsampled_df.No_halt==True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d2ca9c-41a7-439d-9ee7-e0261b919507",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_df#.loc[downsampled_df.No_halt==True]\n",
    "\n",
    "downsampled_df.ExperimentEvents.unique()#.loc[downsampled_df.No_halt==True]\n",
    "downsampled_df.loc[downsampled_df.ExperimentEvents=='Apply halt: 1s']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e861b95b-c014-479c-b027-14e67de8cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_df.loc[downsampled_df.Seconds >87.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a65be3-268c-46a2-a6da-295a2934cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_df.loc[downsampled_df.event ==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f171bb52-31d5-4b53-aa76-51d91a4162ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data = process.pooling_data(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86135f-fffd-4c06-81c8-32ccf2eb7d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Data.reset_index()\n",
    "Data = Data.drop(columns=['level_0'])  # Assuming the column name is 'level_0' after reset_index()\n",
    "Data = Data.set_index('level_1')  # 'level_1' will be the numeric index part\n",
    "Data.index.name = 'Time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9bde1-27cb-409f-8f1f-52a4502d663c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dca954-f381-406b-bcc7-e8dc0a379acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1ef5c-1f79-4c2e-925e-4bd780eebaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20240730_Mismatch_Experiment/GRAB_MMclosed-and-open_190824'\n",
    "#Data.to_csv('GRAB_MMclosed_open_session1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e4d3d6-2b17-45d3-89cc-b451c9486669",
   "metadata": {},
   "outputs": [],
   "source": [
    "B3M7 = Data.loc[Data.mouseID=='B3M7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9335000-5f21-4178-b3f5-f79dd0e4bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "B3M4 = Data.loc[Data.mouseID=='B3M4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9345ecaa-a8c8-4fd3-98bc-a91da6604bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "B3M4.loc[B3M4.ExperimentEvents == 'Block timer elapsed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d0b117-e566-4897-893f-ea1f534c3e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "B3M4.loc[B3M4.LinearPlaybackMismatch_block == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c9d99-3920-4e03-8253-a9bbbee550ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "aeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
