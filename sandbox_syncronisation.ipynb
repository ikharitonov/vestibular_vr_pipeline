{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Extract and align data from Onix, Harp, Sleap, and photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import harp\n",
    "\n",
    "from harp_resources import process, utils\n",
    "from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort0 = False #only read harp data when it exists, not in Cohort0 \n",
    "cohort2 = False\n",
    "\n",
    "#Cohort 1 single OnixDigital file\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2717-2024-12-12T13-00-21') #single onix_digital files\n",
    "\n",
    "#Cohort 1 multiple OnixDigital files \n",
    "data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2718-2024-12-12T13-28-14') #multiple onix_digital file\n",
    "\n",
    "#Cohort 1 with clock accumulation issue marked on google sheet \n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2719-2024-12-12T13-59-38') #multiple onix_digital file\n",
    "\n",
    "#Cohort 0 (no OnixHarp in this Cohort)\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort0/Cohort0_GCaMP_example/B3M3xx-2024-08-08T10-05-26')\n",
    "#cohort0 = True\n",
    "\n",
    "#Cohort 2 N.B. no videodata or photometry in this test set \n",
    "# cohort2 = True\n",
    "# data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_like_test_data/2025-01-13T15-47-26')\n",
    "\n",
    "#Cohort 2 N.B. no photometry in this test set (neitjer videos, but yes video_data)\n",
    "# cohort2 = True\n",
    "# data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_test_longer/2025-02-07T11-50-14')\n",
    "\n",
    "photometry_path = data_path.parent / f\"{data_path.name}_processedData\" / \"photometry\"\n",
    "\n",
    "# h1_datafolder = data_path / 'HarpDataH1' #only if reading separate registers\n",
    "# h2_datafolder = data_path / 'HarpDataH2' #only if reading separate registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h1 and h2 only needed if timestamps are readed separately and not as all harp_streams\n",
    "# h1_reader = harp.create_reader('harp_resources/h1-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "# h2_reader = harp.create_reader('harp_resources/h2-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "\n",
    "session_settings_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "onix_framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "photometry_reader = utils.PhotometryReader(\"Processed_fluorescence\")\n",
    "video_reader1 = utils.Video(\"VideoData1\")\n",
    "video_reader2 = utils.Video(\"VideoData2\")\n",
    "onix_digital_reader = utils.OnixDigitalReader(\"OnixDigital\", columns=[\"Value.Clock\", \"Value.HubClock\", \n",
    "                                                                         \"Value.DigitalInputs\",\n",
    "                                                                         \"Seconds\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read metadata in 2 different ways (to df or to dict, to decide which one is better in the future)\n",
    "print (\"Loading session settings\")\n",
    "session_settings = utils.load_2(session_settings_reader, data_path) #Andrew's, creates ugly df, but used in further analysis code\n",
    "#session_settings = utils.read_SessionSettings(data_path) #Hilde's, creates prety dict, not aware of multiple files\n",
    "\n",
    "# read experiment events, video, processed photometry \n",
    "print (\"Loading experiment events\")\n",
    "experiment_events = utils.load_2(experiment_events_reader, data_path)\n",
    "if not cohort2:\n",
    "    print (\"Loading processed fluorescence\")\n",
    "    photometry_data=pd.read_csv(str(photometry_path)+'/Processed_fluorescence.csv')\n",
    "    print (\"Loading processed fluorescence info\")\n",
    "    photometry_info=pd.read_csv(str(photometry_path)+'/Info.csv')\n",
    "    print (\"Loading processed fluorescence events\")\n",
    "    photometry_events=pd.read_csv(str(photometry_path)+'/Events.csv')\n",
    "    print (\"Loading video data 1\")\n",
    "    video_data1 = utils.load_2(video_reader1, data_path)\n",
    "    print (\"Loading video data 2\")\n",
    "    video_data2 = utils.load_2(video_reader2, data_path)\n",
    "\n",
    "# read Onix data \n",
    "print (\"Loading OnixDigital\")\n",
    "onix_digital = utils.load_2(onix_digital_reader, data_path)\n",
    "if not cohort0:\n",
    "    print (\"Loading OnixHarp\")\n",
    "    onix_harp = utils.load_2(onix_harp_reader, data_path)\n",
    "    # removing possible outliers \n",
    "    onix_harp = utils.detect_and_remove_outliers(\n",
    "    df=onix_harp,\n",
    "    x_column=\"HarpTime\",\n",
    "    y_column=\"Clock\",\n",
    "    verbose=False  # True prints all outliers\n",
    "    )\n",
    "    \n",
    "print (\"Loading OnixAnalogFrameClock\")\n",
    "onix_analog_framecount = utils.load_2(onix_framecount_reader, data_path)\n",
    "print (\"Loading OnixAnalogClock\")\n",
    "onix_analog_clock = utils.read_OnixAnalogClock(data_path)\n",
    "print (\"Loading OnixAnalogData\")\n",
    "onix_analog_data = utils.read_OnixAnalogData(data_path, channels = [0], binarise=True) #channels is a list of AI lines, 0-11\n",
    "\n",
    "#read harp streams and separate registers if needed \n",
    "print (\"Loading H1 and H2 streams as dict or df\")\n",
    "harp_streams = utils.load_registers(data_path, dataframe = True) #loads as df, or if False, as dict \n",
    "\n",
    "# print (\" \")\n",
    "# print (\"loading separate registers from H1 and H2 data\")\n",
    "# print (\"Loading camera triggers\")\n",
    "# camera_triggers = utils.load_harp(h1_reader.Cam0Event, h1_datafolder) #assumes Cam0 triggers both cameras\n",
    "# print (\"Loading flow sensor data\")\n",
    "# flow_sensor = utils.load_harp(h1_reader.OpticalTrackingRead, h1_datafolder)\n",
    "print (\"Done Loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### DEV align Onix, HARP and Photometry data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)  # Forces Python to reload the updated module\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversions = process.photometry_alingment_Cohort1plus(\n",
    "    onix_analog_clock, \n",
    "    onix_analog_framecount,\n",
    "    onix_digital,\n",
    "    photometry_events, \n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### iterate through folders to load OnixHarp and test outliers. \n",
    "### beginning can be used to iterate through folder for batch processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define root directory\n",
    "root_dir = Path(\"/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/\")\n",
    "\n",
    "# Initialize dictionary for storing paths\n",
    "data_paths = {}\n",
    "\n",
    "# List directories one level down and add them to the dictionary\n",
    "for sub_dir in root_dir.iterdir():  # Only iterate one level down\n",
    "    if sub_dir.is_dir() and not sub_dir.name.endswith(\"_processedData\") and not sub_dir.name.startswith(\".\"):\n",
    "        data_paths[sub_dir.name] = sub_dir  # Use the directory name as the key and the full path as the value\n",
    "\n",
    "# Iterate over the dictionary and run the command\n",
    "for key, data_path in data_paths.items():\n",
    "    print(f\"Loading: {key}\")\n",
    "    print \" \"\n",
    "    onix_harp = utils.load_2(onix_harp_reader, data_path)\n",
    "    # removing possible outliers \n",
    "    onix_harp = utils.detect_and_remove_outliers(\n",
    "    df=onix_harp,\n",
    "    x_column=\"HarpTime\",\n",
    "    y_column=\"Clock\",\n",
    "    verbose=False  # True prints all outliers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "aeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
