{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Extract and align data from Onix, Harp, Sleap, and photometry\n",
    "## Cohort 1 and 2 working, Cohort 0: onix_digital Clock column is 0, explore why and/or use timestamps instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import harp\n",
    "import plotly.express as px\n",
    "\n",
    "from harp_resources import process, utils\n",
    "from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort0 = False #only read harp data when it exists, not in Cohort0 \n",
    "cohort2 = False\n",
    "\n",
    "#Cohort 1 vestibular mismatch, multiple OnixDigital files \n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2718-2024-12-12T13-28-14') #multiple onix_digital file\n",
    "\n",
    "#Cohort 1 with clock accumulation issue marked on google sheet, seems fine though\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2719-2024-12-12T13-59-38') #multiple onix_digital file\n",
    "\n",
    "#Cohort 1 visual mismatch \n",
    "data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day3/B6J2718-2024-12-10T12-57-02') \n",
    "\n",
    "#Cohort 0 (no OnixHarp in this Cohort)\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort0/Cohort0_GCaMP_example/B3M3xx-2024-08-08T10-05-26')\n",
    "#cohort0 = True\n",
    "\n",
    "#Cohort 2 N.B. no videodata in this test set \n",
    "#cohort2 = True\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_like_test_data/2025-01-13T15-47-26')\n",
    "\n",
    "#Cohort 2 longer test YES OnixHarp! \n",
    "#N.B. no photometry in this test set (neitjer videos, but yes video_data)\n",
    "#cohort2 = True\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_test_longer/2025-02-10T08-18-59')\n",
    " \n",
    "photometry_path = data_path.parent / f\"{data_path.name}_processedData\" / \"photometry\"\n",
    "\n",
    "h1_datafolder = data_path / 'HarpDataH1' #only if reading separate registers\n",
    "# h2_datafolder = data_path / 'HarpDataH2' #only if reading separate registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h1 and h2 only needed if timestamps are readed separately and not as all harp_streams\n",
    "h1_reader = harp.create_reader('harp_resources/h1-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "# h2_reader = harp.create_reader('harp_resources/h2-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "\n",
    "session_settings_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "onix_framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "#photometry_reader = utils.PhotometryReader(\"Processed_fluorescence\")\n",
    "video_reader1 = utils.Video(\"VideoData1\")\n",
    "video_reader2 = utils.Video(\"VideoData2\")\n",
    "onix_digital_reader = utils.OnixDigitalReader(\"OnixDigital\", columns=[\"Value.Clock\", \"Value.HubClock\", \n",
    "                                                                         \"Value.DigitalInputs\",\n",
    "                                                                         \"Seconds\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#read metadata in 2 different ways (to df or to dict, to decide which one is better in the future)\n",
    "print (\"Loading session settings\")\n",
    "session_settings = utils.load_2(session_settings_reader, data_path) #Andrew's, creates ugly df, but used in further analysis code\n",
    "#session_settings = utils.read_SessionSettings(data_path) #Hilde's, creates prety dict, not aware of multiple files\n",
    "\n",
    "# read experiment events, video, processed photometry \n",
    "print (\"Loading experiment events\")\n",
    "experiment_events = utils.load_2(experiment_events_reader, data_path)\n",
    "\n",
    "print (\"Loading processed fluorescence\")\n",
    "photometry_data=pd.read_csv(str(photometry_path)+'/Processed_fluorescence.csv')\n",
    "print (\"Loading processed fluorescence info\")\n",
    "photometry_info=pd.read_csv(str(photometry_path)+'/Info.csv')\n",
    "print (\"Loading processed fluorescence events\")\n",
    "photometry_events=pd.read_csv(str(photometry_path)+'/Events.csv')\n",
    "\n",
    "if not cohort2:\n",
    "    print (\"Loading video data 1\")\n",
    "    video_data1 = utils.load_2(video_reader1, data_path)\n",
    "    print (\"Loading video data 2\")\n",
    "    video_data2 = utils.load_2(video_reader2, data_path)\n",
    "\n",
    "# read Onix data \n",
    "print (\"Loading OnixDigital\")\n",
    "onix_digital = utils.load_2(onix_digital_reader, data_path)\n",
    "print (\"Loading OnixAnalogFrameClock\")\n",
    "onix_analog_framecount = utils.load_2(onix_framecount_reader, data_path)\n",
    "print (\"Loading OnixAnalogClock\")\n",
    "onix_analog_clock = utils.read_OnixAnalogClock(data_path)\n",
    "print (\"Loading OnixAnalogData\")\n",
    "onix_analog_data = utils.read_OnixAnalogData(data_path, channels = [0], binarise=True) #channels is a list of AI lines, 0-11\n",
    "\n",
    "#read harp streams and separate registers if needed \n",
    "print (\"Loading H1 and H2 streams as dict or df\")\n",
    "harp_streams = utils.load_registers(data_path, dataframe = True) #loads as df, or if False, as dict \n",
    "\n",
    "#read syncronising signal between HARP and ONIX\n",
    "if not cohort0:\n",
    "    print (\"Loading OnixHarp\")\n",
    "    onix_harp = utils.load_2(onix_harp_reader, data_path)\n",
    "    # removing possible outliers \n",
    "    onix_harp = utils.detect_and_remove_outliers(\n",
    "    df=onix_harp,\n",
    "    x_column=\"HarpTime\",\n",
    "    y_column=\"Clock\",\n",
    "    verbose=False  # True prints all outliers\n",
    "    )\n",
    "    onix_harp[\"HarpTime\"] = onix_harp[\"HarpTime\"] + 1 # known issue with current version of ONIX, harp timestamps lag 1 second\n",
    "    print (\"Warning: HarpTime +1s to account for know issue with ONIX\")\n",
    "\n",
    "# print (\" \")\n",
    "# print (\"loading separate registers from H1 and H2 data\")\n",
    "print (\"Loading camera triggers\")\n",
    "camera_triggers = utils.load_harp(h1_reader.Cam0Event, h1_datafolder) #assumes Cam0 triggers both cameras\n",
    "print (\"Loading flow sensor data\")\n",
    "flow_sensor = utils.load_harp(h1_reader.OpticalTrackingRead, h1_datafolder)\n",
    "print (\"Done Loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)\n",
    "importlib.reload(process) # Forces Python to reload the updated module\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "(\n",
    "    conversions, \n",
    "    photometry_sync_events, \n",
    "    harp_to_onix_clock, \n",
    "    onix_time_to_photometry, \n",
    "    onix_to_harp_timestamp,\n",
    "    photometry_to_harp_time\n",
    ") = process.photometry_harp_onix_synchronisation(\n",
    "    onix_analog_data=onix_analog_data,\n",
    "    onix_analog_clock=onix_analog_clock,\n",
    "    onix_analog_framecount=onix_analog_framecount,\n",
    "    onix_digital=onix_digital,\n",
    "    onix_harp=onix_harp,\n",
    "    photometry_events=photometry_events,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# User-defined time window (in seconds)\n",
    "window_start = -1  # Start time relative to halt event\n",
    "window_stop = 5    # Stop time relative to halt event\n",
    "\n",
    "how_many_to_plot = len(experiment_events.query(\"Event == 'Apply halt: 2s'\"))  # Use all halts\n",
    "#how_many_to_plot = 2\n",
    "\n",
    "print (\"Found\",len(experiment_events.query(\"Event == 'Apply halt: 2s'\")),\" number of halts, plotting \", how_many_to_plot)\n",
    "\n",
    "# Efficient filtering\n",
    "block_halts = experiment_events.query(\"Event == 'Apply halt: 2s'\").iloc[:how_many_to_plot]\n",
    "\n",
    "# Define colors for each signal type\n",
    "flow_x_color = \"blue\"\n",
    "flow_y_color = \"orange\"\n",
    "photodiode_color = \"purple\"\n",
    "dfF_470_color = \"green\"\n",
    "dfF_560_color = \"red\"\n",
    "\n",
    "# Initialize lists for storing aligned data\n",
    "aligned_time = np.linspace(window_start, window_stop, 500)  # Fixed time grid for averaging\n",
    "flow_x_aligned = []\n",
    "flow_y_aligned = []\n",
    "photodiode_aligned = []\n",
    "dfF_470_aligned = []\n",
    "dfF_560_aligned = []\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for idx, halt_time in enumerate(block_halts.index):\n",
    "    halt_time_seconds = halt_time.timestamp()\n",
    "\n",
    "    # Define new time range based on user input\n",
    "    min_time = halt_time + pd.DateOffset(seconds=window_start)\n",
    "    max_time = halt_time + pd.DateOffset(seconds=window_stop)\n",
    "\n",
    "    # Extract Optical Tracking Data\n",
    "    optical_x = harp_streams['OpticalTrackingRead0X(46)'].loc[min_time:max_time].dropna()\n",
    "    optical_y = harp_streams['OpticalTrackingRead0Y(46)'].loc[min_time:max_time].dropna()\n",
    "\n",
    "    if not optical_x.empty and not optical_y.empty:\n",
    "        optical_x_rel = (optical_x.index.astype(\"int64\") / 1e9) - halt_time_seconds\n",
    "        optical_y_rel = (optical_y.index.astype(\"int64\") / 1e9) - halt_time_seconds\n",
    "\n",
    "        ax1.plot(optical_x_rel, optical_x, label='Flow X', color=flow_x_color, alpha=0.5)\n",
    "        ax1.plot(optical_y_rel, optical_y, label='Flow Y', color=flow_y_color, alpha=0.5)\n",
    "\n",
    "        # Interpolate for averaging\n",
    "        flow_x_interp = np.interp(aligned_time, optical_x_rel, optical_x, left=np.nan, right=np.nan)\n",
    "        flow_y_interp = np.interp(aligned_time, optical_y_rel, optical_y, left=np.nan, right=np.nan)\n",
    "        flow_x_aligned.append(flow_x_interp)\n",
    "        flow_y_aligned.append(flow_y_interp)\n",
    "\n",
    "# Formatting for Optical Flow\n",
    "ax1.set_xlabel(\"Relative Time (s)\")\n",
    "ax1.set_ylabel(\"Tracking Readout\")\n",
    "ax1.set_title(\"Optical Flow, Photodiode, and Photometry\")\n",
    "\n",
    "# Create separate y-axis for Photodiode\n",
    "ax3 = ax1.twinx()\n",
    "ax3.spines.right.set_position((\"outward\", 60))\n",
    "ax3.set_ylabel(\"Photodiode Signal\")\n",
    "ax3.set_ylim([0, 1.2])\n",
    "\n",
    "# Process ONIX signals (Photodiode)\n",
    "for idx, halt_time in enumerate(block_halts.index):\n",
    "    halt_time_seconds = halt_time.timestamp()\n",
    "\n",
    "    onix_sec_start_time = harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] + window_start)\n",
    "    onix_sec_stop_time = harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] + window_stop)\n",
    "\n",
    "    onix_sec_start_index = np.searchsorted(onix_analog_clock, onix_sec_start_time)\n",
    "    onix_sec_stop_index = np.searchsorted(onix_analog_clock, onix_sec_stop_time)\n",
    "\n",
    "    # Convert Onix timestamps to relative seconds\n",
    "    onix_time_rel = (onix_to_harp_timestamp(onix_analog_clock[onix_sec_start_index:onix_sec_stop_index])\n",
    "                     .astype(\"int64\") / 1e9) - halt_time_seconds\n",
    "\n",
    "    ax3.plot(\n",
    "        onix_time_rel,\n",
    "        onix_analog_data[onix_sec_start_index:onix_sec_stop_index],\n",
    "        label=\"Photodiode\",\n",
    "        color=photodiode_color, alpha=0.8\n",
    "    )\n",
    "\n",
    "    # Interpolate for averaging\n",
    "    photodiode_interp = np.interp(aligned_time, onix_time_rel, onix_analog_data[onix_sec_start_index:onix_sec_stop_index],\n",
    "                                  left=np.nan, right=np.nan)\n",
    "    photodiode_aligned.append(photodiode_interp)\n",
    "\n",
    "# Create second y-axis for photometry\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Fluorescence Signal\")\n",
    "\n",
    "# Convert `TimeStamp` column to seconds if not already done\n",
    "if \"TimeStamp\" in photometry_data.columns:\n",
    "    photometry_data = photometry_data.set_index(\"TimeStamp\")\n",
    "\n",
    "for idx, halt_time in enumerate(block_halts.index):\n",
    "    halt_time_seconds = halt_time.timestamp()\n",
    "\n",
    "    photometry_sec_start_time = onix_time_to_photometry(harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] + window_start))\n",
    "    photometry_sec_stop_time = onix_time_to_photometry(harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] + window_stop))\n",
    "\n",
    "    # Select photometry data using proper time range\n",
    "    photometry_sec = photometry_data.loc[photometry_sec_start_time:photometry_sec_stop_time]\n",
    "\n",
    "    if not photometry_sec.empty:\n",
    "        # Convert photometry timestamps to relative seconds\n",
    "        photometry_time_rel = (photometry_to_harp_time(photometry_sec.index).astype(\"int64\") / 1e9) - halt_time_seconds\n",
    "\n",
    "        ax2.plot(\n",
    "            photometry_time_rel,\n",
    "            photometry_sec['dfF_560'],\n",
    "            label='dfF_560',\n",
    "            color=dfF_560_color\n",
    "        )\n",
    "\n",
    "        ax2.plot(\n",
    "            photometry_time_rel,\n",
    "            photometry_sec['dfF_470'],\n",
    "            label='dfF_470',\n",
    "            color=dfF_470_color\n",
    "        )\n",
    "\n",
    "        # Interpolate for averaging\n",
    "        dfF_560_interp = np.interp(aligned_time, photometry_time_rel, photometry_sec['dfF_560'], left=np.nan, right=np.nan)\n",
    "        dfF_470_interp = np.interp(aligned_time, photometry_time_rel, photometry_sec['dfF_470'], left=np.nan, right=np.nan)\n",
    "        dfF_560_aligned.append(dfF_560_interp)\n",
    "        dfF_470_aligned.append(dfF_470_interp)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# **Second plot: Average and Error Shading**\n",
    "plt.figure(figsize=(10, 6))\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Compute mean and std across trials\n",
    "flow_x_mean = np.nanmean(flow_x_aligned, axis=0)\n",
    "flow_y_mean = np.nanmean(flow_y_aligned, axis=0)\n",
    "photodiode_mean = np.nanmean(photodiode_aligned, axis=0)\n",
    "dfF_560_mean = np.nanmean(dfF_560_aligned, axis=0)\n",
    "dfF_470_mean = np.nanmean(dfF_470_aligned, axis=0)\n",
    "\n",
    "flow_x_std = np.nanstd(flow_x_aligned, axis=0)\n",
    "flow_y_std = np.nanstd(flow_y_aligned, axis=0)\n",
    "photodiode_std = np.nanstd(photodiode_aligned, axis=0)\n",
    "dfF_560_std = np.nanstd(dfF_560_aligned, axis=0)\n",
    "dfF_470_std = np.nanstd(dfF_470_aligned, axis=0)\n",
    "\n",
    "# Plot means with shaded error regions\n",
    "ax1.plot(aligned_time, flow_x_mean, label=\"Flow X (Mean)\", color=flow_x_color)\n",
    "ax1.fill_between(aligned_time, flow_x_mean - flow_x_std, flow_x_mean + flow_x_std, color=flow_x_color, alpha=0.3)\n",
    "\n",
    "ax1.plot(aligned_time, flow_y_mean, label=\"Flow Y (Mean)\", color=flow_y_color)\n",
    "ax1.fill_between(aligned_time, flow_y_mean - flow_y_std, flow_y_mean + flow_y_std, color=flow_y_color, alpha=0.3)\n",
    "\n",
    "ax3 = ax1.twinx()\n",
    "ax3.plot(aligned_time, photodiode_mean, label=\"Photodiode (Mean)\", color=photodiode_color)\n",
    "ax3.fill_between(aligned_time, photodiode_mean - photodiode_std, photodiode_mean + photodiode_std, color=photodiode_color, alpha=0.3)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(aligned_time, dfF_560_mean, label=\"dfF_560 (Mean)\", color=dfF_560_color)\n",
    "ax2.fill_between(aligned_time, dfF_560_mean - dfF_560_std, dfF_560_mean + dfF_560_std, color=dfF_560_color, alpha=0.3)\n",
    "\n",
    "ax2.plot(aligned_time, dfF_470_mean, label=\"dfF_470 (Mean)\", color=dfF_470_color)\n",
    "ax2.fill_between(aligned_time, dfF_470_mean - dfF_470_std, dfF_470_mean + dfF_470_std, color=dfF_470_color, alpha=0.3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "aeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
