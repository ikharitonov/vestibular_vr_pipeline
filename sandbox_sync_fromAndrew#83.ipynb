{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import harp\n",
    "import plotly.express as px\n",
    "\n",
    "from harp_resources import process, utils\n",
    "from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort0 = False #only read harp data when it exists, not in Cohort0 \n",
    "cohort2 = False\n",
    "\n",
    "#Cohort 1 single OnixDigital file\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2717-2024-12-12T13-00-21') #single onix_digital files\n",
    "\n",
    "#Cohort 1 multiple OnixDigital files \n",
    "data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2718-2024-12-12T13-28-14') #multiple onix_digital file\n",
    "\n",
    "#Cohort 1 with clock accumulation issue marked on google sheet \n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2719-2024-12-12T13-59-38') #multiple onix_digital file\n",
    "\n",
    "#Cohort 0 (no OnixHarp in this Cohort)\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort0/Cohort0_GCaMP_example/B3M3xx-2024-08-08T10-05-26')\n",
    "#cohort0 = True\n",
    "\n",
    "#Cohort 2 N.B. no videodata or photometry in this test set \n",
    "# cohort2 = True\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_like_test_data/2025-01-13T15-47-26')\n",
    "\n",
    "#Cohort 2 longer test NO OnixHarp! Clock increasing exponentially according to NORA, but does not show uissue N.B. no photometry in this test set (neitjer videos, but yes video_data)\n",
    "#cohort2 = True\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_test_longer/2025-02-07T16-05-04')\n",
    "\n",
    "#Cohort 2 longer test YES OnixHarp! N.B. no photometry in this test set (neitjer videos, but yes video_data)\n",
    "#cohort2 = True\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_test_longer/2025-02-10T08-18-59')\n",
    " \n",
    "\n",
    "photometry_path = data_path.parent / f\"{data_path.name}_processedData\" / \"photometry\"\n",
    "\n",
    "# h1_datafolder = data_path / 'HarpDataH1' #only if reading separate registers\n",
    "# h2_datafolder = data_path / 'HarpDataH2' #only if reading separate registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h1 and h2 only needed if timestamps are readed separately and not as all harp_streams\n",
    "# h1_reader = harp.create_reader('harp_resources/h1-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "# h2_reader = harp.create_reader('harp_resources/h2-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "\n",
    "session_settings_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "onix_framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "#photometry_reader = utils.PhotometryReader(\"Processed_fluorescence\")\n",
    "video_reader1 = utils.Video(\"VideoData1\")\n",
    "video_reader2 = utils.Video(\"VideoData2\")\n",
    "onix_digital_reader = utils.OnixDigitalReader(\"OnixDigital\", columns=[\"Value.Clock\", \"Value.HubClock\", \n",
    "                                                                         \"Value.DigitalInputs\",\n",
    "                                                                         \"Seconds\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read metadata in 2 different ways (to df or to dict, to decide which one is better in the future)\n",
    "print (\"Loading session settings\")\n",
    "session_settings = utils.load_2(session_settings_reader, data_path) #Andrew's, creates ugly df, but used in further analysis code\n",
    "#session_settings = utils.read_SessionSettings(data_path) #Hilde's, creates prety dict, not aware of multiple files\n",
    "\n",
    "# read experiment events, video, processed photometry \n",
    "print (\"Loading experiment events\")\n",
    "experiment_events = utils.load_2(experiment_events_reader, data_path)\n",
    "if not cohort2:\n",
    "    print (\"Loading processed fluorescence\")\n",
    "    photometry_data=pd.read_csv(str(photometry_path)+'/Processed_fluorescence.csv')\n",
    "    print (\"Loading processed fluorescence info\")\n",
    "    photometry_info=pd.read_csv(str(photometry_path)+'/Info.csv')\n",
    "    print (\"Loading processed fluorescence events\")\n",
    "    photometry_events=pd.read_csv(str(photometry_path)+'/Events.csv')\n",
    "    print (\"Loading video data 1\")\n",
    "    video_data1 = utils.load_2(video_reader1, data_path)\n",
    "    print (\"Loading video data 2\")\n",
    "    video_data2 = utils.load_2(video_reader2, data_path)\n",
    "\n",
    "# read Onix data \n",
    "print (\"Loading OnixDigital\")\n",
    "onix_digital = utils.load_2(onix_digital_reader, data_path)\n",
    "print (\"Loading OnixAnalogFrameClock\")\n",
    "onix_analog_framecount = utils.load_2(onix_framecount_reader, data_path)\n",
    "print (\"Loading OnixAnalogClock\")\n",
    "onix_analog_clock = utils.read_OnixAnalogClock(data_path)\n",
    "print (\"Loading OnixAnalogData\")\n",
    "onix_analog_data = utils.read_OnixAnalogData(data_path, channels = [0], binarise=True, method = 'adaptive', verbose = True) #channels is a list of AI lines, 0-11\n",
    "halt_count = (experiment_events[\"Event\"] == \"Halt\").sum()\n",
    "print(f'Halts in exp_events: {halt_count}, same as falling edges?')\n",
    "\n",
    "#read harp streams and separate registers if needed \n",
    "print (\"Loading H1 and H2 streams as dict or df\")\n",
    "harp_streams = utils.load_registers(data_path, dataframe = True) #loads as df, or if False, as dict \n",
    "\n",
    "#read syncronising signal between HARP and ONIX\n",
    "if not cohort0:\n",
    "    print (\"Loading OnixHarp\")\n",
    "    onix_harp = utils.load_2(onix_harp_reader, data_path)\n",
    "    # removing possible outliers \n",
    "    onix_harp = utils.detect_and_remove_outliers(\n",
    "    df=onix_harp,\n",
    "    x_column=\"HarpTime\",\n",
    "    y_column=\"Clock\",\n",
    "    verbose=False  # True prints all outliers\n",
    "    )\n",
    "\n",
    "# print (\" \")\n",
    "# print (\"loading separate registers from H1 and H2 data\")\n",
    "# print (\"Loading camera triggers\")\n",
    "# camera_triggers = utils.load_harp(h1_reader.Cam0Event, h1_datafolder) #assumes Cam0 triggers both cameras\n",
    "# print (\"Loading flow sensor data\")\n",
    "# flow_sensor = utils.load_harp(h1_reader.OpticalTrackingRead, h1_datafolder)\n",
    "print (\"Done Loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)\n",
    "importlib.reload(process) # Forces Python to reload the updated module\n",
    "None\n",
    "onix_analog_data = utils.read_OnixAnalogData(data_path, channels = [0], binarise=True, method = 'adaptive', refractory = 300, verbose = True) #channels is a list of AI lines, 0-11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_data(start_time_sec=0, end_time_sec=1):\n",
    "    \"\"\"\n",
    "    Plots the specified time window of harp_streams and experiment_events.\n",
    "\n",
    "    Parameters:\n",
    "    - start_time_sec (int): Start of the time window (in seconds).\n",
    "    - end_time_sec (int): End of the time window (in seconds).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define downsampling factors\n",
    "    harp_streams_downsample_factor = 10\n",
    "    onix_analog_data_downsample_factor = 10000\n",
    "    experiment_events_downsample_factor = 1  \n",
    "\n",
    "    # ✅ Create a copy of harp_streams before modification\n",
    "    harp_streams_copy = harp_streams.copy()\n",
    "\n",
    "    # Interpolate and fix NaNs in OpticalTrackingRead0Y(46) in the copied dataframe\n",
    "    harp_streams_copy[\"OpticalTrackingRead0Y(46)\"] = (\n",
    "        harp_streams_copy[\"OpticalTrackingRead0Y(46)\"]\n",
    "        .interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "    )\n",
    "\n",
    "    # Convert datetime index to elapsed seconds\n",
    "    start_time = harp_streams_copy.index[0]  \n",
    "    harp_streams_copy[\"ElapsedTime\"] = (harp_streams_copy.index - start_time).total_seconds()\n",
    "    experiment_events[\"ElapsedTime\"] = (experiment_events.index - start_time).total_seconds()\n",
    "\n",
    "    # ✅ Filter data based on the time window\n",
    "    harp_streams_filtered = harp_streams_copy[\n",
    "        (harp_streams_copy[\"ElapsedTime\"] >= start_time_sec) &\n",
    "        (harp_streams_copy[\"ElapsedTime\"] <= end_time_sec)\n",
    "    ]\n",
    "    \n",
    "    experiment_events_filtered = experiment_events[\n",
    "        (experiment_events[\"ElapsedTime\"] >= start_time_sec) &\n",
    "        (experiment_events[\"ElapsedTime\"] <= end_time_sec)\n",
    "    ]\n",
    "\n",
    "    # Downsample data\n",
    "    harp_streams_downsampled = harp_streams_filtered.iloc[::harp_streams_downsample_factor]\n",
    "    onix_analog_data_1d = onix_analog_data.squeeze()\n",
    "    onix_analog_data_downsampled = onix_analog_data_1d[:len(harp_streams_filtered)][::onix_analog_data_downsample_factor]\n",
    "    experiment_events_downsampled = experiment_events_filtered.iloc[::experiment_events_downsample_factor]\n",
    "\n",
    "    # ✅ Plot Optical Tracking (Now fully interpolated, but original `harp_streams` is unchanged)\n",
    "    fig1 = go.Figure()\n",
    "\n",
    "    fig1.add_trace(go.Scatter(\n",
    "        x=harp_streams_downsampled.index,\n",
    "        y=harp_streams_downsampled[\"OpticalTrackingRead0Y(46)\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Optical Tracking Read Y\"\n",
    "    ))\n",
    "\n",
    "    fig1.update_layout(\n",
    "        title=f\"Optical Tracking Read Y ({start_time_sec}-{end_time_sec} sec)\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Values\",\n",
    "        dragmode=\"pan\"\n",
    "    )\n",
    "\n",
    "    fig1.show()\n",
    "\n",
    "    # ✅ Plot Analog Data\n",
    "    fig2 = go.Figure()\n",
    "\n",
    "    fig2.add_trace(go.Scatter(\n",
    "        x=harp_streams_downsampled.index[:len(onix_analog_data_downsampled)],\n",
    "        y=onix_analog_data_downsampled,\n",
    "        mode=\"lines\",\n",
    "        name=\"Analog Data\"\n",
    "    ))\n",
    "\n",
    "    fig2.update_layout(\n",
    "        title=f\"Analog Data ({start_time_sec}-{end_time_sec} sec)\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Values\",\n",
    "        dragmode=\"pan\"\n",
    "    )\n",
    "\n",
    "    fig2.show()\n",
    "\n",
    "    # ✅ Plot Experiment Events (Scatter)\n",
    "    fig3 = go.Figure()\n",
    "\n",
    "    fig3.add_trace(go.Scatter(\n",
    "        x=experiment_events_downsampled.index,\n",
    "        y=experiment_events_downsampled[\"Event\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=\"black\"),\n",
    "        name=\"Experiment Events\"\n",
    "    ))\n",
    "\n",
    "    fig3.update_layout(\n",
    "        title=f\"Experiment Events Over Time ({start_time_sec}-{end_time_sec} sec)\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Event\",\n",
    "        dragmode=\"pan\"\n",
    "    )\n",
    "\n",
    "    fig3.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_data(start_time_sec=0, end_time_sec=3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "issue is that analog data does not have timestamp... need to do the conversion first for analog_data, then for harp with onix_harp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "aeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
