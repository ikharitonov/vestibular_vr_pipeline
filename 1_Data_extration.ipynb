{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab4fa08-6412-44d1-a14e-35b5225cfcd2",
   "metadata": {},
   "source": [
    "# Extract and align data from Onix, Harp, Sleap, and photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ae21d",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e9aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import harp\n",
    "from pathlib import Path\n",
    "\n",
    "from harp_resources import process, utils\n",
    "from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeb3733-1577-47fe-9c5c-d95c778f97b0",
   "metadata": {},
   "source": [
    "# Define paths\n",
    "Define a root directory through wich you can loop to get both photometry data and onix data. \n",
    "May need to be done in a different way if file structures are changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1d2dade-655e-4655-9a8c-782a04e525a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/Users/nora/Desktop/Cohort0_GCaMP_example'\n",
    "\n",
    "#initialize sets to ensure uniqueness\n",
    "data_paths_set = set()\n",
    "photometry_paths_set = set()\n",
    "\n",
    "data_paths = []\n",
    "photometry_paths = []\n",
    "\n",
    "for dirpath, subdirs, files in os.walk(rootdir):\n",
    "    #data paths\n",
    "    if 'ExperimentEvents' in dirpath:\n",
    "        trimmed_path = dirpath[:-17]\n",
    "        if trimmed_path not in data_paths_set:\n",
    "            data_paths_set.add(trimmed_path)\n",
    "            data_paths.append(trimmed_path)\n",
    "\n",
    "    #photometry paths\n",
    "    for x in files:\n",
    "        if 'Processed_fluorescence.csv' in x:\n",
    "            if dirpath not in photometry_paths_set:\n",
    "                photometry_paths_set.add(dirpath)\n",
    "                photometry_paths.append(dirpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e8b984-e71f-4550-882e-e354d249ae77",
   "metadata": {},
   "source": [
    "### Have a look to ensure that the photometry and onix data paths match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1c561ed-9448-4891-b9e9-6bf56d862edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/nora/Desktop/Cohort0_GCaMP_example/2024-08-08T10-05-26_B3M3']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447c76ba-7cad-4a4d-8fa5-05425513fe81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/nora/Desktop/Cohort0_GCaMP_example/2024-08-08T10-05-26_B3M3/photometry_processed']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photometry_paths "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c02b7-ba42-4246-8b54-32de8485bf1b",
   "metadata": {},
   "source": [
    "# Call funcitons to extract data and align timestamps\n",
    "All the function calls needed can be arranged in a function or called one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf8844bc-ca31-4c75-b71a-2cdbbd06805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_extraction_makeh5(data_path, photometry_path, make_h5=True, eyes=False):\n",
    "    print(f'\\n Running extraction for {data_path.split(\"/\")[-1][20:]} for session {data_path.split(\"/\")[-2]}')\n",
    "\n",
    "    # Load session settings and conversions\n",
    "    SessionSettings = utils.read_SessionSettings(Path(data_path), print_contents=True)\n",
    "    conversions = process.calculate_conversions_second_approach(Path(data_path), Path(photometry_path), verbose=False)\n",
    "    streams = utils.load_registers(Path(data_path))\n",
    "\n",
    "    # Load photometry data and align timestamps\n",
    "    Photometry = utils.read_fluorescence(Path(photometry_path))\n",
    "    Photometry['HARP Timestamps'] = conversions['photometry_to_harp_time'](Photometry['TimeStamp'])\n",
    "\n",
    "    # Load OnixAnalog data\n",
    "    OnixAnalogClock = utils.read_OnixAnalogClock(Path(data_path))\n",
    "    OnixAnalogData = utils.read_OnixAnalogData(Path(data_path), binarise=True)\n",
    "    ExperimentEvents = utils.read_ExperimentEvents(Path(data_path))\n",
    "    photodiode_series = pd.Series(OnixAnalogData[:, 0], index=conversions['onix_to_harp_timestamp'](OnixAnalogClock))\n",
    "\n",
    "    print('Adding Photometry, Eye Movements, and Photodiode to the streams')\n",
    "    # Add Photometry and Photodiode streams\n",
    "    streams = process.reformat_and_add_many_streams(\n",
    "        streams, Photometry, 'Photometry', ['470_dfF', 'z_470'], index_column_name='HARP Timestamps'\n",
    "    )\n",
    "    streams = process.add_stream(streams, 'ONIX', photodiode_series, 'Photodiode')\n",
    "\n",
    "    # Process videography data if eyes=True\n",
    "    if eyes:\n",
    "        print('  Checking for and processing videography data...')\n",
    "        try:\n",
    "            # Load videography data\n",
    "            VideoData1, VideoData2, VideoData1_Has_Sleap, VideoData2_Has_Sleap = lp.load_videography_data(data_path)\n",
    "\n",
    "            if VideoData2_Has_Sleap:\n",
    "                print('  Processing VideoData2 with SLEAP data...')\n",
    "\n",
    "                # Interpolate missing data\n",
    "                VideoData2 = VideoData2.interpolate()\n",
    "\n",
    "                # Extract coordinates and compute transformations\n",
    "                columns_of_interest = [\n",
    "                    'left.x', 'left.y', 'center.x', 'center.y', 'right.x', 'right.y',\n",
    "                    'p1.x', 'p1.y', 'p2.x', 'p2.y', 'p3.x', 'p3.y', 'p4.x', 'p4.y',\n",
    "                    'p5.x', 'p5.y', 'p6.x', 'p6.y', 'p7.x', 'p7.y', 'p8.x', 'p8.y'\n",
    "                ]\n",
    "                coordinates_dict = lp.get_coordinates_dict(VideoData2, columns_of_interest)\n",
    "\n",
    "                # Calculate transformations\n",
    "                theta = lp.find_horizontal_axis_angle(VideoData2, 'left', 'center')\n",
    "                center_point = lp.get_left_right_center_point(coordinates_dict)\n",
    "\n",
    "                reformatted_coordinates_dict = lp.get_reformatted_coordinates_dict(coordinates_dict, ['left', 'right', 'center'] + [f'p{i}' for i in range(1, 9)])\n",
    "                centered_coordinates_dict = lp.get_centered_coordinates_dict(reformatted_coordinates_dict, center_point)\n",
    "                rotated_coordinates_dict = lp.get_rotated_coordinates_dict(centered_coordinates_dict, theta)\n",
    "\n",
    "                # Extract ellipse parameters\n",
    "                columns_of_interest = [f'p{i}' for i in range(1, 9)]\n",
    "                ellipse_parameters_data, ellipse_center_points_data = lp.get_fitted_ellipse_parameters(\n",
    "                    rotated_coordinates_dict, columns_of_interest\n",
    "                )\n",
    "\n",
    "                # Compute additional metrics\n",
    "                average_diameter = np.mean([ellipse_parameters_data[:, 0], ellipse_parameters_data[:, 1]], axis=0)\n",
    "\n",
    "                # Prepare SLEAP video data for streams\n",
    "                SleapVideoData2 = process.convert_arrays_to_dataframe(\n",
    "                    ['Seconds', 'Ellipse.Diameter', 'Ellipse.Angle', 'Ellipse.Center.X', 'Ellipse.Center.Y'],\n",
    "                    [VideoData2['Seconds'].values, average_diameter, ellipse_parameters_data[:, 2],\n",
    "                     ellipse_center_points_data[:, 0], ellipse_center_points_data[:, 1]]\n",
    "                )\n",
    "\n",
    "                streams = process.reformat_and_add_many_streams(\n",
    "                    streams, SleapVideoData2, 'SleapVideoData2',\n",
    "                    ['Ellipse.Diameter', 'Ellipse.Angle', 'Ellipse.Center.X', 'Ellipse.Center.Y']\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing videography data: {e}\")\n",
    "\n",
    "    # Display timepoint info for streams\n",
    "    _ = process.get_timepoint_info(streams, print_all=True)\n",
    "\n",
    "    # Resample streams\n",
    "    resampled_streams = process.pad_and_resample(streams, resampling_period='1 ms', method='linear')\n",
    "    _ = process.get_timepoint_info(resampled_streams, print_all=True)\n",
    "\n",
    "    # Apply unit conversions for optical tracking sensor streams\n",
    "    print('  Applying linear and angular conversion to Optical tracking sensor streams (cm/sec and degrees/sec)')\n",
    "    resampled_streams['H1']['OpticalTrackingRead0X(46)'] = process.running_unit_conversion(\n",
    "        resampled_streams['H1']['OpticalTrackingRead0X(46)'] * 100\n",
    "    )\n",
    "    resampled_streams['H1']['OpticalTrackingRead0Y(46)'] = process.rotation_unit_conversion(\n",
    "        resampled_streams['H1']['OpticalTrackingRead0Y(46)']\n",
    "    )\n",
    "\n",
    "    print(' - Streams are extracted and can be used or made to h5')\n",
    "\n",
    "    if make_h5:\n",
    "        # Define streams to save, including SLEAP data if processed\n",
    "        streams_to_save_pattern = {\n",
    "            'Photometry': ['470_dfF', 'z_470'],\n",
    "            'ONIX': ['Photodiode'],\n",
    "        }\n",
    "        if eyes:\n",
    "            streams_to_save_pattern['SleapVideoData2'] = ['Ellipse.Diameter', 'Ellipse.Center.X', 'Ellipse.Center.Y']\n",
    "\n",
    "        process.save_streams_as_h5(Path(data_path), resampled_streams, streams_to_save_pattern, SessionSettings)\n",
    "        print('Streams saved as h5 file \\n')\n",
    "\n",
    "    return data_path, resampled_streams, streams_to_save_pattern\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16978260-08f5-4109-a576-9bbcf7fd8070",
   "metadata": {},
   "source": [
    "## Call the function\n",
    "Below, the funciton is called with only one path combo, and then with several through a loop\n",
    "If all seems to work, you can set make_h5 to True, or you can use the resampled streams and save pattern daved to the dict made in the loop to make the h5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3121375d-875b-41c2-83e1-4f91cb368797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Running extraction for B3M3 for session Cohort0_GCaMP_example\n",
      "{\n",
      "    \"seconds\": 768959.520256,\n",
      "    \"value\": {\n",
      "        \"motorSettings\": {\n",
      "            \"nominalPulseInterval\": 200,\n",
      "            \"initialPulseInterval\": 200,\n",
      "            \"pulseStepInterval\": 2,\n",
      "            \"pulsePeriod\": 10\n",
      "        },\n",
      "        \"blocks\": [\n",
      "            {\n",
      "                \"alias\": \"LinearMismatch\",\n",
      "                \"playbackFilePath\": \"\",\n",
      "                \"blockGainModifier\": 1.0,\n",
      "                \"flowXToVisualGain\": 0.0008,\n",
      "                \"flowYToVisualGain\": 0.0,\n",
      "                \"rotaryToVisualGain\": 0.0,\n",
      "                \"playbackToVisualGain\": 0.0,\n",
      "                \"stimulus\": {\n",
      "                    \"type\": 0,\n",
      "                    \"spatialFrequency\": 28.8,\n",
      "                    \"offset1\": -90.0,\n",
      "                    \"extent1\": 180.0,\n",
      "                    \"offset2\": 90.0,\n",
      "                    \"extent2\": 180.0,\n",
      "                    \"path\": \"\"\n",
      "                },\n",
      "                \"flowXToMotorGain\": 0.0,\n",
      "                \"flowYToMotorGain\": 0.0,\n",
      "                \"playbackToMotorGain\": 0.0,\n",
      "                \"totalRuntime\": 900.0,\n",
      "                \"haltProtocol\": {\n",
      "                    \"randomDelay\": 0.5,\n",
      "                    \"minumumDelay\": 0.1,\n",
      "                    \"haltTime\": 1.0,\n",
      "                    \"haltGain\": 1.0\n",
      "                },\n",
      "                \"flowXToRunGain\": 0.0008,\n",
      "                \"flowYToRunGain\": 0.0,\n",
      "                \"playbackToRunGain\": 0.0,\n",
      "                \"decayTimestep\": 0.0,\n",
      "                \"runThresholdDecay\": 0.0,\n",
      "                \"runThreshold\": 325.0,\n",
      "                \"haltProbability\": 0.4\n",
      "            },\n",
      "            {\n",
      "                \"alias\": \"LinearPlaybackMismatch\",\n",
      "                \"playbackFilePath\": \"Z:/data/ONIX/20240730_Mismatch_Experiment/playback_file_B2M4_5.csv\",\n",
      "                \"blockGainModifier\": 1.0,\n",
      "                \"flowXToVisualGain\": 0.0,\n",
      "                \"flowYToVisualGain\": 0.0,\n",
      "                \"rotaryToVisualGain\": 0.0,\n",
      "                \"playbackToVisualGain\": 0.0008,\n",
      "                \"stimulus\": {\n",
      "                    \"type\": 0,\n",
      "                    \"spatialFrequency\": 28.8,\n",
      "                    \"offset1\": -90.0,\n",
      "                    \"extent1\": 180.0,\n",
      "                    \"offset2\": 90.0,\n",
      "                    \"extent2\": 180.0,\n",
      "                    \"path\": \"\"\n",
      "                },\n",
      "                \"flowXToMotorGain\": 0.0,\n",
      "                \"flowYToMotorGain\": 0.0,\n",
      "                \"playbackToMotorGain\": 0.0,\n",
      "                \"totalRuntime\": 900.0,\n",
      "                \"haltProtocol\": {\n",
      "                    \"randomDelay\": 0.5,\n",
      "                    \"minumumDelay\": 0.1,\n",
      "                    \"haltTime\": 1.0,\n",
      "                    \"haltGain\": 1.0\n",
      "                },\n",
      "                \"flowXToRunGain\": 0.0,\n",
      "                \"flowYToRunGain\": 0.0,\n",
      "                \"playbackToRunGain\": 0.0008,\n",
      "                \"decayTimestep\": 0.0,\n",
      "                \"runThresholdDecay\": 0.0,\n",
      "                \"runThreshold\": 110.0,\n",
      "                \"haltProbability\": 0.4\n",
      "            }\n",
      "        ],\n",
      "        \"metadata\": {\n",
      "            \"runGain\": 1.0,\n",
      "            \"rootPath\": \"D:/TrialLogicTestData/\",\n",
      "            \"animalId\": \"B3M3\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Dataset 2024-08-08T10-05-26_B3M3 contains following registers:\n",
      "H1: [32, 46, 33]\n",
      "H2: [42, 39]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nora/Documents/vestibular_vr_pipeline/harp_resources/process.py:380: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  sorted_filenames = pd.to_datetime(pd.Series([x.split('_')[1].split('.')[0] for x in filenames])).sort_values()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registers loaded in 1.59 seconds.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'TimeStamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/aeon/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TimeStamp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_path, resampled_streams, streams_to_save_pattern \u001b[38;5;241m=\u001b[39m run_extraction_makeh5(\n\u001b[1;32m      2\u001b[0m     data_paths[\u001b[38;5;241m0\u001b[39m], photometry_paths[\u001b[38;5;241m0\u001b[39m], make_h5\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, eyes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m, in \u001b[0;36mrun_extraction_makeh5\u001b[0;34m(data_path, photometry_path, make_h5, eyes)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load photometry data and align timestamps\u001b[39;00m\n\u001b[1;32m     10\u001b[0m Photometry \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mread_fluorescence(Path(photometry_path))\n\u001b[0;32m---> 11\u001b[0m Photometry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHARP Timestamps\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m conversions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphotometry_to_harp_time\u001b[39m\u001b[38;5;124m'\u001b[39m](Photometry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimeStamp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Load OnixAnalog data\u001b[39;00m\n\u001b[1;32m     14\u001b[0m OnixAnalogClock \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mread_OnixAnalogClock(Path(data_path))\n",
      "File \u001b[0;32m~/miniconda3/envs/aeon/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/aeon/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TimeStamp'"
     ]
    }
   ],
   "source": [
    "data_path, resampled_streams, streams_to_save_pattern = run_extraction_makeh5(\n",
    "    data_paths[0], photometry_paths[0], make_h5=False, eyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081748b8-50d4-4fa4-850b-8c8e872d62ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Photometry' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Photometry\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Photometry' is not defined"
     ]
    }
   ],
   "source": [
    "Photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d567b6ee-973f-4ed9-874c-c3b26064ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_dict = {}\n",
    "for i, (datapath, photometry_path) in enumerate(zip(data_paths, photometry_paths)):\n",
    "    print(datapath)\n",
    "    print(photometry_path)\n",
    "    stream_dict[f'dataset_{i}'] = {}\n",
    "    data_path, resampled_streams, streams_to_save_pattern = run_extraction_makeh5(\n",
    "    data_paths[0], photometry_paths[0], make_h5=False, eyes=True)\n",
    "    stream_dict[f'dataset_{i}']['resampled_streams'] = resampled_streams\n",
    "    stream_dict[f'dataset_{i}']['streams_to_save_pattern'] = streams_to_save_pattern\n",
    "    stream_dict[f'dataset_{i}']['data_path'] = data_path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318fbe6-941f-4cbc-aa20-360f4eda4b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc51ae-dc5e-46b3-917b-7b8fa6e00726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!! ONLY RUN IF YOU WANT TO MAKE NEW H5 FILES !!!!\n",
    "\n",
    "for dataset, data_dict in stream_dict.items():\n",
    "\n",
    "    process.save_streams_as_h5(Path(data_dict['data_path']), data_dict['resampled_streams'], data_dict['streams_to_save_pattern'], SessionSettings)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf38d29-f87e-444a-be2f-244cf0ab64b9",
   "metadata": {},
   "source": [
    "# Extracting Noras data\n",
    "\n",
    "This is adapted from the instructions given by Andrew for reading the temporary onix digital file versions (the weird ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e2274d2-c911-40ec-a7a2-fdbeaff36376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# photometry_path = '/Volumes/RanczLab/Nora_Cohort1_training/Training_day4/B6J2717-2024-11-28T09-37-55/photometry'\n",
    "# data_path = '/Volumes/RanczLab/Nora_Cohort1_training/Training_day4/B6J2717-2024-11-28T09-37-55/'\n",
    "\n",
    "photometry_path = '/Users/nora/Desktop/Cohort0_GCaMP_example/2024-08-08T10-05-26_B3M3/photometry_processed/'\n",
    "data_path = '/Users/nora/Desktop/Cohort0_GCaMP_example/2024-08-08T10-05-26_B3M3/'\n",
    "\n",
    "h1_datafolder = data_path+'HarpDataH1'\n",
    "h2_datafolder = data_path+'HarpDataH2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec62ce30-5a18-48ac-a840-2107db22c634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>filtered_470</th>\n",
       "      <th>filtered_560</th>\n",
       "      <th>filtered_410</th>\n",
       "      <th>470_dfF</th>\n",
       "      <th>560_dfF</th>\n",
       "      <th>410_dfF</th>\n",
       "      <th>z_470</th>\n",
       "      <th>z_560</th>\n",
       "      <th>z_410</th>\n",
       "      <th>Time</th>\n",
       "      <th>mouseID</th>\n",
       "      <th>Area</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.011110</td>\n",
       "      <td>60.750</td>\n",
       "      <td>9.094</td>\n",
       "      <td>13.336148</td>\n",
       "      <td>-3.401339</td>\n",
       "      <td>-0.118508</td>\n",
       "      <td>4.800172</td>\n",
       "      <td>-1.124964</td>\n",
       "      <td>-0.468415</td>\n",
       "      <td>4.059622</td>\n",
       "      <td>2024-08-08 12:08:44.011110</td>\n",
       "      <td>B3M3</td>\n",
       "      <td>v1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.044442</td>\n",
       "      <td>64.074</td>\n",
       "      <td>9.135</td>\n",
       "      <td>13.238875</td>\n",
       "      <td>1.884158</td>\n",
       "      <td>0.332083</td>\n",
       "      <td>4.035766</td>\n",
       "      <td>0.947863</td>\n",
       "      <td>1.160582</td>\n",
       "      <td>3.405835</td>\n",
       "      <td>2024-08-08 12:08:44.044442</td>\n",
       "      <td>B3M3</td>\n",
       "      <td>v1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.077776</td>\n",
       "      <td>68.062</td>\n",
       "      <td>9.120</td>\n",
       "      <td>13.146754</td>\n",
       "      <td>8.225483</td>\n",
       "      <td>0.167613</td>\n",
       "      <td>3.311848</td>\n",
       "      <td>3.434756</td>\n",
       "      <td>0.565979</td>\n",
       "      <td>2.786679</td>\n",
       "      <td>2024-08-08 12:08:44.077776</td>\n",
       "      <td>B3M3</td>\n",
       "      <td>v1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.111110</td>\n",
       "      <td>69.676</td>\n",
       "      <td>9.104</td>\n",
       "      <td>13.067576</td>\n",
       "      <td>10.791906</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>2.689640</td>\n",
       "      <td>4.441237</td>\n",
       "      <td>-0.068331</td>\n",
       "      <td>2.254514</td>\n",
       "      <td>2024-08-08 12:08:44.111110</td>\n",
       "      <td>B3M3</td>\n",
       "      <td>v1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.144442</td>\n",
       "      <td>69.759</td>\n",
       "      <td>9.099</td>\n",
       "      <td>13.008761</td>\n",
       "      <td>10.923885</td>\n",
       "      <td>-0.062481</td>\n",
       "      <td>2.227452</td>\n",
       "      <td>4.492995</td>\n",
       "      <td>-0.265862</td>\n",
       "      <td>1.859211</td>\n",
       "      <td>2024-08-08 12:08:44.144442</td>\n",
       "      <td>B3M3</td>\n",
       "      <td>v1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56863</th>\n",
       "      <td>1910.191877</td>\n",
       "      <td>63.243</td>\n",
       "      <td>8.760</td>\n",
       "      <td>12.889807</td>\n",
       "      <td>0.562784</td>\n",
       "      <td>-1.391212</td>\n",
       "      <td>1.292666</td>\n",
       "      <td>0.429656</td>\n",
       "      <td>-4.947367</td>\n",
       "      <td>1.059701</td>\n",
       "      <td>2024-08-08 12:40:19.191877</td>\n",
       "      <td>B3M3</td>\n",
       "      <td>v1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56864</th>\n",
       "      <td>1910.225208</td>\n",
       "      <td>63.311</td>\n",
       "      <td>8.817</td>\n",
       "      <td>12.900128</td>\n",
       "      <td>0.670911</td>\n",
       "      <td>-0.749560</td>\n",
       "      <td>1.373770</td>\n",
       "      <td>0.472061</td>\n",
       "      <td>-2.683990</td>\n",
       "      <td>1.129068</td>\n",
       "      <td>2024-08-08 12:40:19.225208</td>\n",
       "      <td>B3M3</td>\n",
       "      <td>v1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56865</th>\n",
       "      <td>1910.258534</td>\n",
       "      <td>62.999</td>\n",
       "      <td>8.777</td>\n",
       "      <td>12.915368</td>\n",
       "      <td>0.174799</td>\n",
       "      <td>-1.199809</td>\n",
       "      <td>1.493536</td>\n",
       "      <td>0.277499</td>\n",
       "      <td>-4.272205</td>\n",
       "      <td>1.231503</td>\n",
       "      <td>2024-08-08 12:40:19.258534</td>\n",
       "      <td>B3M3</td>\n",
       "      <td>v1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56866</th>\n",
       "      <td>1910.291861</td>\n",
       "      <td>62.518</td>\n",
       "      <td>8.807</td>\n",
       "      <td>12.934425</td>\n",
       "      <td>-0.590040</td>\n",
       "      <td>-0.862088</td>\n",
       "      <td>1.643294</td>\n",
       "      <td>-0.022449</td>\n",
       "      <td>-3.080921</td>\n",
       "      <td>1.359588</td>\n",
       "      <td>2024-08-08 12:40:19.291861</td>\n",
       "      <td>B3M3</td>\n",
       "      <td>v1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56867</th>\n",
       "      <td>1910.325190</td>\n",
       "      <td>62.862</td>\n",
       "      <td>8.777</td>\n",
       "      <td>12.955353</td>\n",
       "      <td>-0.043045</td>\n",
       "      <td>-1.199769</td>\n",
       "      <td>1.807750</td>\n",
       "      <td>0.192067</td>\n",
       "      <td>-4.272065</td>\n",
       "      <td>1.500245</td>\n",
       "      <td>2024-08-08 12:40:19.325190</td>\n",
       "      <td>B3M3</td>\n",
       "      <td>v1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56868 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TimeStamp  filtered_470  filtered_560  filtered_410    470_dfF  \\\n",
       "0        15.011110        60.750         9.094     13.336148  -3.401339   \n",
       "1        15.044442        64.074         9.135     13.238875   1.884158   \n",
       "2        15.077776        68.062         9.120     13.146754   8.225483   \n",
       "3        15.111110        69.676         9.104     13.067576  10.791906   \n",
       "4        15.144442        69.759         9.099     13.008761  10.923885   \n",
       "...            ...           ...           ...           ...        ...   \n",
       "56863  1910.191877        63.243         8.760     12.889807   0.562784   \n",
       "56864  1910.225208        63.311         8.817     12.900128   0.670911   \n",
       "56865  1910.258534        62.999         8.777     12.915368   0.174799   \n",
       "56866  1910.291861        62.518         8.807     12.934425  -0.590040   \n",
       "56867  1910.325190        62.862         8.777     12.955353  -0.043045   \n",
       "\n",
       "        560_dfF   410_dfF     z_470     z_560     z_410  \\\n",
       "0     -0.118508  4.800172 -1.124964 -0.468415  4.059622   \n",
       "1      0.332083  4.035766  0.947863  1.160582  3.405835   \n",
       "2      0.167613  3.311848  3.434756  0.565979  2.786679   \n",
       "3     -0.007842  2.689640  4.441237 -0.068331  2.254514   \n",
       "4     -0.062481  2.227452  4.492995 -0.265862  1.859211   \n",
       "...         ...       ...       ...       ...       ...   \n",
       "56863 -1.391212  1.292666  0.429656 -4.947367  1.059701   \n",
       "56864 -0.749560  1.373770  0.472061 -2.683990  1.129068   \n",
       "56865 -1.199809  1.493536  0.277499 -4.272205  1.231503   \n",
       "56866 -0.862088  1.643294 -0.022449 -3.080921  1.359588   \n",
       "56867 -1.199769  1.807750  0.192067 -4.272065  1.500245   \n",
       "\n",
       "                             Time mouseID Area Sex  \n",
       "0      2024-08-08 12:08:44.011110    B3M3   v1   m  \n",
       "1      2024-08-08 12:08:44.044442    B3M3   v1   m  \n",
       "2      2024-08-08 12:08:44.077776    B3M3   v1   m  \n",
       "3      2024-08-08 12:08:44.111110    B3M3   v1   m  \n",
       "4      2024-08-08 12:08:44.144442    B3M3   v1   m  \n",
       "...                           ...     ...  ...  ..  \n",
       "56863  2024-08-08 12:40:19.191877    B3M3   v1   m  \n",
       "56864  2024-08-08 12:40:19.225208    B3M3   v1   m  \n",
       "56865  2024-08-08 12:40:19.258534    B3M3   v1   m  \n",
       "56866  2024-08-08 12:40:19.291861    B3M3   v1   m  \n",
       "56867  2024-08-08 12:40:19.325190    B3M3   v1   m  \n",
       "\n",
       "[56868 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(str(photometry_path)+'/Processed_fluorescence.csv') #Processed_fluorescence.csv #Fluorescence.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae09c1-ebcc-4b97-9490-dd15e8310de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f6cb3eb-66fa-4df6-8b56-3e26e1fa1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from andrew:\n",
    "#Changed didgital output file\n",
    "h1_reader = harp.create_reader('harp_resources/h1-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "h2_reader = harp.create_reader('harp_resources/h2-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "session_data_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "photometry_reader = utils.PhotometryReader(\"Processed_fluorescence\")\n",
    "video_reader = utils.Video(\"VideoData1\")\n",
    "onix_digital_reader = utils.TimestampedCsvReader(\"OnixDigital\", columns=[\"Clock\", \"HubClock\", \n",
    "                                                                         \"DigitalInputs0\",\n",
    "                                                                         \"DigitalInputs1\",\n",
    "                                                                         \"DigitalInputs2\",\n",
    "                                                                         \"DigitalInputs3\",\n",
    "                                                                         \"DigitalInputs4\",\n",
    "                                                                         \"DigitalInputs5\"\n",
    "                                                                         \"DigitalInputs6\",\n",
    "                                                                         \"DigitalInputs7\",\n",
    "                                                                         \"DigitalInputs8\",\n",
    "                                                                         \"Buttons\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0db153-c7a6-428a-9666-7ade0695d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ccd5ff7-0f81-443b-9195-48e93efc1db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DotMap(randomDelay=0.5, minumumDelay=0.1, haltTime=1.0, haltGain=1.0)\n"
     ]
    }
   ],
   "source": [
    "# read metadata\n",
    "session_settings = utils.load_2(session_data_reader, data_path)\n",
    "\n",
    "print(session_settings.iloc[0]['metadata'].blocks[0].haltProtocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66cfd125-532a-4946-97c3-c6852c65790b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nora/Desktop/Cohort0_GCaMP_example/2024-08-08T10-05-26_B3M3/HarpDataH1/HarpDataH1_46_*.bin\n",
      "/Users/nora/Desktop/Cohort0_GCaMP_example/2024-08-08T10-05-26_B3M3/HarpDataH1/HarpDataH1_32_*.bin\n"
     ]
    }
   ],
   "source": [
    "# read harp streams, experiment events, video\n",
    "flow_sensor = utils.load_harp(h1_reader.OpticalTrackingRead, h1_datafolder)\n",
    "camera_triggers = utils.load_harp(h1_reader.Cam0Event, h1_datafolder)\n",
    "experiment_events = utils.load_2(experiment_events_reader, data_path)\n",
    "video_data = utils.load_2(video_reader, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872df99-e409-4435-8a63-3e1380fb0e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
