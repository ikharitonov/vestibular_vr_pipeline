{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab4fa08-6412-44d1-a14e-35b5225cfcd2",
   "metadata": {},
   "source": [
    "# Extract and align data from Onix, Harp, Sleap, and photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ae21d",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e9aa9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'harp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mharp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mharp_resources\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process, utils\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msleap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_and_process \u001b[38;5;28;01mas\u001b[39;00m lp\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'harp'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import harp\n",
    "\n",
    "from harp_resources import process, utils\n",
    "from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeb3733-1577-47fe-9c5c-d95c778f97b0",
   "metadata": {},
   "source": [
    "# Define paths\n",
    "Define a root directory through wich you can loop to get both photometry data and onix data. \n",
    "May need to be done in a different way if file structures are changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d2dade-655e-4655-9a8c-782a04e525a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/Volumes/RanczLab/20240730_Mismatch_Experiment/G8_MMclosed-and-open_070824'\n",
    "\n",
    "#initialize sets to ensure uniqueness\n",
    "data_paths_set = set()\n",
    "photometry_paths_set = set()\n",
    "\n",
    "data_paths = []\n",
    "photometry_paths = []\n",
    "\n",
    "for dirpath, subdirs, files in os.walk(rootdir):\n",
    "    #data paths\n",
    "    if 'ExperimentEvents' in dirpath:\n",
    "        trimmed_path = dirpath[:-17]\n",
    "        if trimmed_path not in data_paths_set:\n",
    "            data_paths_set.add(trimmed_path)\n",
    "            data_paths.append(trimmed_path)\n",
    "\n",
    "    #photometry paths\n",
    "    for x in files:\n",
    "        if 'Processed_fluorescence.csv' in x:\n",
    "            if dirpath not in photometry_paths_set:\n",
    "                photometry_paths_set.add(dirpath)\n",
    "                photometry_paths.append(dirpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e8b984-e71f-4550-882e-e354d249ae77",
   "metadata": {},
   "source": [
    "### Have a look to ensure that the photometry and onix data paths match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c561ed-9448-4891-b9e9-6bf56d862edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c76ba-7cad-4a4d-8fa5-05425513fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "photometry_paths "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c02b7-ba42-4246-8b54-32de8485bf1b",
   "metadata": {},
   "source": [
    "# Call funcitons to extract data and align timestamps\n",
    "All the function calls needed can be arranged in a function or called one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8844bc-ca31-4c75-b71a-2cdbbd06805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_extraction_makeh5(data_path, photometry_path, make_h5=False, eyes=False):\n",
    "    print(f'\\n Running extraction for {data_path.split(\"/\")[-1][20:]} for session {data_path.split(\"/\")[-2]}')\n",
    "\n",
    "    # Load session settings and conversions\n",
    "    SessionSettings = utils.read_SessionSettings(Path(data_path), print_contents=True)\n",
    "    conversions = process.calculate_conversions_second_approach(Path(data_path), Path(photometry_path), verbose=False)\n",
    "    streams = utils.load_registers(Path(data_path))\n",
    "\n",
    "    # Load photometry data and align timestamps\n",
    "    Photometry = utils.read_fluorescence(Path(photometry_path))\n",
    "    Photometry['HARP Timestamps'] = conversions['photometry_to_harp_time'](Photometry['TimeStamp'])\n",
    "\n",
    "    # Load OnixAnalog data\n",
    "    OnixAnalogClock = utils.read_OnixAnalogClock(Path(data_path))\n",
    "    OnixAnalogData = utils.read_OnixAnalogData(Path(data_path), binarise=True)\n",
    "    ExperimentEvents = utils.read_ExperimentEvents(Path(data_path))\n",
    "    photodiode_series = pd.Series(OnixAnalogData[:, 0], index=conversions['onix_to_harp_timestamp'](OnixAnalogClock))\n",
    "\n",
    "    print('Adding Photometry, Eye Movements, and Photodiode to the streams')\n",
    "    # Add Photometry and Photodiode streams\n",
    "    streams = process.reformat_and_add_many_streams(\n",
    "        streams, Photometry, 'Photometry', ['470_dfF', 'z_470'], index_column_name='HARP Timestamps'\n",
    "    )\n",
    "    streams = process.add_stream(streams, 'ONIX', photodiode_series, 'Photodiode')\n",
    "\n",
    "    # Process videography data if eyes=True\n",
    "    if eyes:\n",
    "        print('  Checking for and processing videography data...')\n",
    "        try:\n",
    "            # Load videography data\n",
    "            VideoData1, VideoData2, VideoData1_Has_Sleap, VideoData2_Has_Sleap = lp.load_videography_data(data_path)\n",
    "\n",
    "            if VideoData2_Has_Sleap:\n",
    "                print('  Processing VideoData2 with SLEAP data...')\n",
    "\n",
    "                # Interpolate missing data\n",
    "                VideoData2 = VideoData2.interpolate()\n",
    "\n",
    "                # Extract coordinates and compute transformations\n",
    "                columns_of_interest = [\n",
    "                    'left.x', 'left.y', 'center.x', 'center.y', 'right.x', 'right.y',\n",
    "                    'p1.x', 'p1.y', 'p2.x', 'p2.y', 'p3.x', 'p3.y', 'p4.x', 'p4.y',\n",
    "                    'p5.x', 'p5.y', 'p6.x', 'p6.y', 'p7.x', 'p7.y', 'p8.x', 'p8.y'\n",
    "                ]\n",
    "                coordinates_dict = lp.get_coordinates_dict(VideoData2, columns_of_interest)\n",
    "\n",
    "                # Calculate transformations\n",
    "                theta = lp.find_horizontal_axis_angle(VideoData2, 'left', 'center')\n",
    "                center_point = lp.get_left_right_center_point(coordinates_dict)\n",
    "\n",
    "                reformatted_coordinates_dict = lp.get_reformatted_coordinates_dict(coordinates_dict, ['left', 'right', 'center'] + [f'p{i}' for i in range(1, 9)])\n",
    "                centered_coordinates_dict = lp.get_centered_coordinates_dict(reformatted_coordinates_dict, center_point)\n",
    "                rotated_coordinates_dict = lp.get_rotated_coordinates_dict(centered_coordinates_dict, theta)\n",
    "\n",
    "                # Extract ellipse parameters\n",
    "                columns_of_interest = [f'p{i}' for i in range(1, 9)]\n",
    "                ellipse_parameters_data, ellipse_center_points_data = lp.get_fitted_ellipse_parameters(\n",
    "                    rotated_coordinates_dict, columns_of_interest\n",
    "                )\n",
    "\n",
    "                # Compute additional metrics\n",
    "                average_diameter = np.mean([ellipse_parameters_data[:, 0], ellipse_parameters_data[:, 1]], axis=0)\n",
    "\n",
    "                # Prepare SLEAP video data for streams\n",
    "                SleapVideoData2 = process.convert_arrays_to_dataframe(\n",
    "                    ['Seconds', 'Ellipse.Diameter', 'Ellipse.Angle', 'Ellipse.Center.X', 'Ellipse.Center.Y'],\n",
    "                    [VideoData2['Seconds'].values, average_diameter, ellipse_parameters_data[:, 2],\n",
    "                     ellipse_center_points_data[:, 0], ellipse_center_points_data[:, 1]]\n",
    "                )\n",
    "\n",
    "                streams = process.reformat_and_add_many_streams(\n",
    "                    streams, SleapVideoData2, 'SleapVideoData2',\n",
    "                    ['Ellipse.Diameter', 'Ellipse.Angle', 'Ellipse.Center.X', 'Ellipse.Center.Y']\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing videography data: {e}\")\n",
    "\n",
    "    # Display timepoint info for streams\n",
    "    _ = process.get_timepoint_info(streams, print_all=True)\n",
    "\n",
    "    # Resample streams\n",
    "    resampled_streams = process.pad_and_resample(streams, resampling_period='1 ms', method='linear')\n",
    "    _ = process.get_timepoint_info(resampled_streams, print_all=True)\n",
    "\n",
    "    # Apply unit conversions for optical tracking sensor streams\n",
    "    print('  Applying linear and angular conversion to Optical tracking sensor streams (cm/sec and degrees/sec)')\n",
    "    resampled_streams['H1']['OpticalTrackingRead0X(46)'] = process.running_unit_conversion(\n",
    "        resampled_streams['H1']['OpticalTrackingRead0X(46)'] * 100\n",
    "    )\n",
    "    resampled_streams['H1']['OpticalTrackingRead0Y(46)'] = process.rotation_unit_conversion(\n",
    "        resampled_streams['H1']['OpticalTrackingRead0Y(46)']\n",
    "    )\n",
    "\n",
    "    print(' - Streams are extracted and can be used or made to h5')\n",
    "\n",
    "    if make_h5:\n",
    "        # Define streams to save, including SLEAP data if processed\n",
    "        streams_to_save_pattern = {\n",
    "            'Photometry': ['470_dfF', 'z_470'],\n",
    "            'ONIX': ['Photodiode'],\n",
    "        }\n",
    "        if eyes:\n",
    "            streams_to_save_pattern['SleapVideoData2'] = ['Ellipse.Diameter', 'Ellipse.Center.X', 'Ellipse.Center.Y']\n",
    "\n",
    "        process.save_streams_as_h5(Path(data_path), resampled_streams, streams_to_save_pattern, SessionSettings)\n",
    "        print('Streams saved as h5 file \\n')\n",
    "\n",
    "    return data_path, resampled_streams, streams_to_save_pattern\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16978260-08f5-4109-a576-9bbcf7fd8070",
   "metadata": {},
   "source": [
    "## Call the function\n",
    "Below, the funciton is called with only one path combo, and then with several through a loop\n",
    "If all seems to work, you can set make_h5 to True, or you can use the resampled streams and save pattern daved to the dict made in the loop to make the h5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3121375d-875b-41c2-83e1-4f91cb368797",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_extraction_makeh5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_path, resampled_streams, streams_to_save_pattern \u001b[38;5;241m=\u001b[39m run_extraction_makeh5(\n\u001b[1;32m      2\u001b[0m     data_paths[\u001b[38;5;241m1\u001b[39m], photometry_paths[\u001b[38;5;241m1\u001b[39m], make_h5\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, eyes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_extraction_makeh5' is not defined"
     ]
    }
   ],
   "source": [
    "data_path, resampled_streams, streams_to_save_pattern = run_extraction_makeh5(\n",
    "    data_paths[1], photometry_paths[1], make_h5=False, eyes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d567b6ee-973f-4ed9-874c-c3b26064ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_dict = {}\n",
    "for i, (datapath, photometry_path) in enumerate(zip(data_paths, photometry_paths)):\n",
    "    print(datapath)\n",
    "    print(photometry_path)\n",
    "    stream_dict[f'dataset_{i}'] = {}\n",
    "    data_path, resampled_streams, streams_to_save_pattern = run_extraction_makeh5(\n",
    "    data_paths[1], photometry_paths[1], make_h5=False, eyes=True)\n",
    "    stream_dict[f'dataset_{i}']['resampled_streams'] = resampled_streams\n",
    "    stream_dict[f'dataset_{i}']['streams_to_save_pattern'] = streams_to_save_pattern\n",
    "    stream_dict[f'dataset_{i}']['data_path'] = data_path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69fc51ae-dc5e-46b3-917b-7b8fa6e00726",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stream_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!!! ONLY RUN IF YOU WANT TO MAKE NEW H5 FILES !!!!\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset, data_dict \u001b[38;5;129;01min\u001b[39;00m stream_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      5\u001b[0m     process\u001b[38;5;241m.\u001b[39msave_streams_as_h5(Path(data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m'\u001b[39m]), data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresampled_streams\u001b[39m\u001b[38;5;124m'\u001b[39m], data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreams_to_save_pattern\u001b[39m\u001b[38;5;124m'\u001b[39m], SessionSettings)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stream_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#!!! ONLY RUN IF YOU WANT TO MAKE NEW H5 FILES !!!!\n",
    "\n",
    "for dataset, data_dict in stream_dict.items():\n",
    "\n",
    "    process.save_streams_as_h5(Path(data_dict['data_path']), data_dict['resampled_streams'], data_dict['streams_to_save_pattern'], SessionSettings)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf38d29-f87e-444a-be2f-244cf0ab64b9",
   "metadata": {},
   "source": [
    "# Extracting Noras data\n",
    "\n",
    "This is adapted from the instructions given by Andrew for reading the temporary onix digital file versions (the weird ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2274d2-c911-40ec-a7a2-fdbeaff36376",
   "metadata": {},
   "outputs": [],
   "source": [
    "photometry_path = '/Volumes/RanczLab/Nora_Cohort1_training/Training_day4/B6J2717-2024-11-28T09-37-55/photometry'\n",
    "data_path = '/Volumes/RanczLab/Nora_Cohort1_training/Training_day4/B6J2717-2024-11-28T09-37-55/'\n",
    "\n",
    "photometry_path = '/Volumes/RanczLab/Nora_Cohort1_training/Visual_mismatch_day1/B6J2717/photometry_processed'\n",
    "data_path = '/Volumes/RanczLab/Nora_Cohort1_training/Visual_mismatch_day1/B6J2717/'\n",
    "\n",
    "h1_datafolder = data_path+'HarpDataH1'\n",
    "h2_datafolder = data_path+'HarpDataH2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62ce30-5a18-48ac-a840-2107db22c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(str(photometry_path)+'/Processed_fluorescence.csv') #Processed_fluorescence.csv #Fluorescence.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae09c1-ebcc-4b97-9490-dd15e8310de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6cb3eb-66fa-4df6-8b56-3e26e1fa1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from andrew:\n",
    "#Changed didgital output file\n",
    "h1_reader = harp.create_reader('harp_resources/h1-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "h2_reader = harp.create_reader('harp_resources/h2-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "session_data_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "photometry_reader = utils.PhotometryReader(\"Processed_fluorescence\")\n",
    "video_reader = utils.Video(\"VideoData1\")\n",
    "onix_digital_reader = utils.TimestampedCsvReader(\"OnixDigital\", columns=[\"Clock\", \"HubClock\", \n",
    "                                                                         \"DigitalInputs0\",\n",
    "                                                                         \"DigitalInputs1\",\n",
    "                                                                         \"DigitalInputs2\",\n",
    "                                                                         \"DigitalInputs3\",\n",
    "                                                                         \"DigitalInputs4\",\n",
    "                                                                         \"DigitalInputs5\"\n",
    "                                                                         \"DigitalInputs6\",\n",
    "                                                                         \"DigitalInputs7\",\n",
    "                                                                         \"DigitalInputs8\",\n",
    "                                                                         \"Buttons\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0db153-c7a6-428a-9666-7ade0695d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd5ff7-0f81-443b-9195-48e93efc1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read metadata\n",
    "session_settings = utils.load_2(session_data_reader, data_path)\n",
    "\n",
    "print(session_settings.iloc[0]['metadata'].blocks[0].haltProtocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cfd125-532a-4946-97c3-c6852c65790b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
