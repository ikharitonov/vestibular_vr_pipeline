{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Batch Extract and align data from Onix, Harp, Sleap, and photometry\n",
    "## Under development, currently overwrites all the data, will need processing and saving steps at the end of every iteration. But this means iterating accross animals for both photometry and onix data (currently separate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import harp\n",
    "from pprint import pprint\n",
    "\n",
    "from harp_resources import process, utils\n",
    "from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define root directory\n",
    "root_dir = Path(\"/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/\")\n",
    "data_paths = {}\n",
    "photometry_paths = {}\n",
    "# List directories one level down and populate both dictionaries\n",
    "for sub_dir in root_dir.iterdir():  # Only iterate one level down\n",
    "    if sub_dir.is_dir() and not sub_dir.name.endswith(\"_processedData\") and not sub_dir.name.startswith(\".\"):\n",
    "        # Add to data_paths\n",
    "        data_paths[sub_dir.name] = sub_dir\n",
    "    if sub_dir.is_dir() and sub_dir.name.endswith(\"_processedData\")and not sub_dir.name.startswith(\".\"):\n",
    "        processed_photometry_path = sub_dir / \"photometry\"\n",
    "        photometry_paths[sub_dir.name] = processed_photometry_path\n",
    "# Print all the paths\n",
    "print (\"Data paths detected\")\n",
    "for path in data_paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h1 and h2 only needed if timestamps are readed separately and not as all harp_streams\n",
    "h1_reader = harp.create_reader('harp_resources/h1-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "h2_reader = harp.create_reader('harp_resources/h2-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "session_settings_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "onix_framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "photometry_reader = utils.PhotometryReader(\"Processed_fluorescence\")\n",
    "video_reader1 = utils.Video(\"VideoData1\")\n",
    "video_reader2 = utils.Video(\"VideoData2\")\n",
    "onix_digital_reader = utils.OnixDigitalReader(\"OnixDigital\", columns=[\"Value.Clock\", \"Value.HubClock\", \n",
    "                                                                         \"Value.DigitalInputs\",\n",
    "                                                                         \"Seconds\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, photometry_path in photometry_paths.items():\n",
    "    print (\" \")\n",
    "    print(f\"Loading Fluoresce: {key}\")\n",
    "    if not cohort2:\n",
    "        print (\"Loading processed fluorescence\")\n",
    "        photometry_data=pd.read_csv(str(photometry_path)+'/Processed_fluorescence.csv')\n",
    "        print (\"Loading processed fluorescence info\")\n",
    "        photometry_info=pd.read_csv(str(photometry_path)+'/Info.csv')\n",
    "        print (\"Loading processed fluorescence events\")\n",
    "        photometry_events=pd.read_csv(str(photometry_path)+'/Events.csv')\n",
    "    \n",
    "# Iterate over the dictionary and run the command\n",
    "for key, data_path in data_paths.items():\n",
    "    print (\" \")\n",
    "    print(f\"Loading: {key}\")\n",
    "    print (\"Loading session settings\")\n",
    "    session_settings = utils.load_2(session_settings_reader, data_path)\n",
    "    print (\"Loading experiment events\")\n",
    "    experiment_events = utils.load_2(experiment_events_reader, data_path)\n",
    "    print (\"Loading video data 1\")\n",
    "    video_data1 = utils.load_2(video_reader1, data_path)\n",
    "    print (\"Loading video data 2\")\n",
    "    video_data2 = utils.load_2(video_reader2, data_path)\n",
    "    print (\"Loading OnixDigital\")\n",
    "    onix_digital = utils.load_2(onix_digital_reader, data_path)\n",
    "    if not cohort0:\n",
    "        print (\"Loading OnixHarp\")\n",
    "        onix_harp = utils.load_2(onix_harp_reader, data_path)\n",
    "        # removing possible outliers \n",
    "        onix_harp = utils.detect_and_remove_outliers(\n",
    "        df=onix_harp,\n",
    "        x_column=\"HarpTime\",\n",
    "        y_column=\"Clock\",\n",
    "        verbose=False  # True prints all outliers\n",
    "        )\n",
    "    print (\"Loading OnixAnalogFrameClock\")\n",
    "    onix_analog_framecount = utils.load_2(onix_framecount_reader, data_path)\n",
    "    print (\"Loading OnixAnalogClock\")\n",
    "    onix_analog_clock = utils.read_OnixAnalogClock(data_path)\n",
    "    print (\"Loading OnixAnalogData\")\n",
    "    onix_analog_data = utils.read_OnixAnalogData(data_path, channels = [0], binarise=True) #channels is a list of AI lines, 0-11\n",
    "    print (\"Loading H1 and H2 streams as dict or df (default)\")\n",
    "    harp_streams = utils.load_registers(data_path, dataframe = True) #loads as df, or if False, as dict\n",
    "print (\"Done Loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "aeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
