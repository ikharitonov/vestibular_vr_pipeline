{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Extract and align data from Onix, Harp, Sleap, and photometry\n",
    "## Cohort 1 and 2 working, Cohort 0: onix_digital Clock column is 0, explore why and/or use timestamps instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import harp\n",
    "import plotly.express as px\n",
    "\n",
    "from harp_resources import process, utils\n",
    "from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort0 = False #only read harp data when it exists, not in Cohort0 \n",
    "cohort2 = False\n",
    "\n",
    "#Cohort 1 vestibular mismatch, multiple OnixDigital files \n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2718-2024-12-12T13-28-14') #multiple onix_digital file\n",
    "\n",
    "#Cohort 1 with clock accumulation issue marked on google sheet, seems fine though\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2719-2024-12-12T13-59-38') #multiple onix_digital file\n",
    "\n",
    "#Cohort 1 visual mismatch \n",
    "data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day3/B6J2718-2024-12-10T12-57-02') \n",
    "\n",
    "#Cohort 0 (no OnixHarp in this Cohort)\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort0/Cohort0_GCaMP_example/B3M3xx-2024-08-08T10-05-26')\n",
    "#cohort0 = True\n",
    "\n",
    "#Cohort 2 N.B. no videodata in this test set \n",
    "#cohort2 = True\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_like_test_data/2025-01-13T15-47-26')\n",
    "\n",
    "#Cohort 2 longer test YES OnixHarp! \n",
    "#N.B. no photometry in this test set (neitjer videos, but yes video_data)\n",
    "#cohort2 = True\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_test_longer/2025-02-10T08-18-59')\n",
    " \n",
    "photometry_path = data_path.parent / f\"{data_path.name}_processedData\" / \"photometry\"\n",
    "\n",
    "h1_datafolder = data_path / 'HarpDataH1' #only if reading separate registers\n",
    "# h2_datafolder = data_path / 'HarpDataH2' #only if reading separate registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h1 and h2 only needed if timestamps are readed separately and not as all harp_streams\n",
    "h1_reader = harp.create_reader('harp_resources/h1-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "# h2_reader = harp.create_reader('harp_resources/h2-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "\n",
    "session_settings_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "onix_framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "#photometry_reader = utils.PhotometryReader(\"Processed_fluorescence\")\n",
    "video_reader1 = utils.Video(\"VideoData1\")\n",
    "video_reader2 = utils.Video(\"VideoData2\")\n",
    "onix_digital_reader = utils.OnixDigitalReader(\"OnixDigital\", columns=[\"Value.Clock\", \"Value.HubClock\", \n",
    "                                                                         \"Value.DigitalInputs\",\n",
    "                                                                         \"Seconds\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#read metadata in 2 different ways (to df or to dict, to decide which one is better in the future)\n",
    "print (\"Loading session settings\")\n",
    "session_settings = utils.load_2(session_settings_reader, data_path) #Andrew's, creates ugly df, but used in further analysis code\n",
    "#session_settings = utils.read_SessionSettings(data_path) #Hilde's, creates prety dict, not aware of multiple files\n",
    "\n",
    "# read experiment events, video, processed photometry \n",
    "print (\"Loading experiment events\")\n",
    "experiment_events = utils.load_2(experiment_events_reader, data_path)\n",
    "\n",
    "print (\"Loading processed fluorescence\")\n",
    "photometry_data=pd.read_csv(str(photometry_path)+'/Processed_fluorescence.csv')\n",
    "print (\"Loading processed fluorescence info\")\n",
    "photometry_info=pd.read_csv(str(photometry_path)+'/Info.csv')\n",
    "print (\"Loading processed fluorescence events\")\n",
    "photometry_events=pd.read_csv(str(photometry_path)+'/Events.csv')\n",
    "\n",
    "if not cohort2:\n",
    "    print (\"Loading video data 1\")\n",
    "    video_data1 = utils.load_2(video_reader1, data_path)\n",
    "    print (\"Loading video data 2\")\n",
    "    video_data2 = utils.load_2(video_reader2, data_path)\n",
    "\n",
    "# read Onix data \n",
    "print (\"Loading OnixDigital\")\n",
    "onix_digital = utils.load_2(onix_digital_reader, data_path)\n",
    "print (\"Loading OnixAnalogFrameClock\")\n",
    "onix_analog_framecount = utils.load_2(onix_framecount_reader, data_path)\n",
    "print (\"Loading OnixAnalogClock\")\n",
    "onix_analog_clock = utils.read_OnixAnalogClock(data_path)\n",
    "print (\"Loading OnixAnalogData\")\n",
    "onix_analog_data = utils.read_OnixAnalogData(data_path, channels = [0], binarise=True) #channels is a list of AI lines, 0-11\n",
    "\n",
    "#read harp streams and separate registers if needed \n",
    "print (\"Loading H1 and H2 streams as dict or df\")\n",
    "harp_streams = utils.load_registers(data_path, dataframe = True) #loads as df, or if False, as dict \n",
    "\n",
    "#read syncronising signal between HARP and ONIX\n",
    "if not cohort0:\n",
    "    print (\"Loading OnixHarp\")\n",
    "    onix_harp = utils.load_2(onix_harp_reader, data_path)\n",
    "    # removing possible outliers \n",
    "    onix_harp = utils.detect_and_remove_outliers(\n",
    "    df=onix_harp,\n",
    "    x_column=\"HarpTime\",\n",
    "    y_column=\"Clock\",\n",
    "    verbose=False  # True prints all outliers\n",
    "    )\n",
    "    onix_harp[\"HarpTime\"] = onix_harp[\"HarpTime\"] + 1 # known issue with current version of ONIX, harp timestamps lag 1 second\n",
    "    print (\"Warning: HarpTime +1s to account for know issue with ONIX\")\n",
    "\n",
    "# print (\" \")\n",
    "# print (\"loading separate registers from H1 and H2 data\")\n",
    "print (\"Loading camera triggers\")\n",
    "camera_triggers = utils.load_harp(h1_reader.Cam0Event, h1_datafolder) #assumes Cam0 triggers both cameras\n",
    "print (\"Loading flow sensor data\")\n",
    "flow_sensor = utils.load_harp(h1_reader.OpticalTrackingRead, h1_datafolder)\n",
    "print (\"Done Loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### DEV align Onix, HARP and Photometry data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)\n",
    "importlib.reload(process) # Forces Python to reload the updated module\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "(\n",
    "    conversions, \n",
    "    photometry_sync_events, \n",
    "    harp_to_onix_clock, \n",
    "    onix_time_to_photometry, \n",
    "    onix_to_harp_timestamp,\n",
    "    photometry_to_harp_time\n",
    ") = process.photometry_harp_onix_synchronisation(\n",
    "    onix_analog_data=onix_analog_data,\n",
    "    onix_analog_clock=onix_analog_clock,\n",
    "    onix_analog_framecount=onix_analog_framecount,\n",
    "    onix_digital=onix_digital,\n",
    "    onix_harp=onix_harp,\n",
    "    photometry_events=photometry_events,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "photometry_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "sec_start = block_halts.index[idx]\n",
    "sec_stop = block_halts.index[idx+1]\n",
    "min_time = sec_start - pd.DateOffset(seconds=1)\n",
    "max_time = sec_stop + pd.DateOffset(seconds=0.5)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Interpolate or drop NaNs for Optical Tracking Data\n",
    "optical_x = harp_streams['OpticalTrackingRead0X(46)'].loc[min_time:max_time].dropna()\n",
    "optical_y = harp_streams['OpticalTrackingRead0Y(46)'].loc[min_time:max_time].dropna()\n",
    "\n",
    "# Plot Optical Tracking Readout (Flow) with NaN-handling\n",
    "plt.plot(optical_x, label='Flow X')\n",
    "plt.plot(optical_y, label='Flow Y')\n",
    "\n",
    "# Extract camera triggers and drop NaNs\n",
    "camera_triggers = harp_streams['Cam0Event(32)'].dropna()\n",
    "\n",
    "# Plot Camera Triggers as scatter points\n",
    "plt.scatter(\n",
    "    camera_triggers[min_time:max_time].index,\n",
    "    np.ones((1, len(camera_triggers[min_time:max_time]))) * -10, \n",
    "    s=1, c='k', label='Camera Trigger'\n",
    ")\n",
    "\n",
    "# Mark the halt command region\n",
    "plt.axvspan(sec_start, sec_start + pd.DateOffset(seconds=0.1), color='black', alpha=0.2, label='Block Start')\n",
    "\n",
    "# Formatting\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Tracking Readout\")\n",
    "plt.legend()\n",
    "plt.title(\"Optical Flow and Camera Triggers\")\n",
    "plt.show()\n",
    "\n",
    "# overlay the onix photodiode signal in converted time\n",
    "onix_sec_start_time = harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] - 1)\n",
    "onix_sec_start_index = np.where(onix_analog_clock >= onix_sec_start_time)[0][0]\n",
    "\n",
    "onix_sec_stop_time = harp_to_onix_clock(block_halts.iloc[idx+1][\"Seconds\"])\n",
    "onix_sec_stop_index = np.where(onix_analog_clock >= onix_sec_stop_time)[0][0]\n",
    "plt.plot(\n",
    "    onix_to_harp_timestamp(onix_analog_clock[onix_sec_start_index:onix_sec_stop_index]),\n",
    "    onix_analog_data[onix_sec_start_index:onix_sec_stop_index],  # Remove the \", 0\"\n",
    "    label='Photodiode'\n",
    ")\n",
    "# overlay photometry\n",
    "photometry_sec_start_time = onix_time_to_photometry(onix_sec_start_time)\n",
    "photometry_sec_stop_time = onix_time_to_photometry(onix_sec_stop_time)\n",
    "\n",
    "# Ensure TimeStamp is the index\n",
    "if \"TimeStamp\" in photometry_data.columns:\n",
    "    photometry_data = photometry_data.set_index(\"TimeStamp\")\n",
    "\n",
    "# Now filter safely\n",
    "photometry_sec = photometry_data.loc[photometry_sec_start_time:photometry_sec_stop_time]\n",
    "\n",
    "#photometry_sec = photometry_data[0].loc[(photometry_data[0].index >= photometry_sec_start_time) & (photometry_data[0].index <= photometry_sec_stop_time)]\n",
    "\n",
    "plt.plot(photometry_to_harp_time(photometry_sec.index), photometry_sec['dfF_560'], label='dfF_560')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(onix_analog_data.shape)  # Check the number of dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example, see harp data, experiment events, onix data for a given window, synchronised.\n",
    "# where did the LinearRegularMismatch block start (approximately)?\n",
    "#block_start = experiment_events[experiment_events[\"Event\"].eq(\"DrumBase block started\")]\n",
    "block_start = experiment_events[experiment_events[\"Event\"].eq(\"DrumWithReverseHalt block started\")]\n",
    "print(block_start)\n",
    "\n",
    "# Get the first 20 halt times after this block started\n",
    "block_halts = experiment_events[(experiment_events[\"Event\"].eq(\"Apply halt: 2s\")) & (experiment_events.index > block_start.index[0])].iloc[0:20]\n",
    "\n",
    "# Plot flow sensor and camera triggers during given halt period\n",
    "idx = 0\n",
    "sec_start = block_halts.index[idx]\n",
    "sec_stop = block_halts.index[idx+1]\n",
    "min_time = sec_start - pd.DateOffset(seconds=1)\n",
    "max_time = sec_stop + pd.DateOffset(seconds=0.5)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(flow_sensor['OpticalTrackingRead0X'][min_time:max_time], label='Flow X')\n",
    "plt.plot(flow_sensor['OpticalTrackingRead0Y'][min_time:max_time], label='Flow Y')\n",
    "plt.scatter(camera_triggers[min_time:max_time].index, np.ones((1, len(camera_triggers[min_time:max_time]))) * -10, s=1, c='k', label='Camera Trigger')\n",
    "plt.axvspan(sec_start, sec_start + pd.DateOffset(seconds=0.1), color='black', alpha=0.2, label='Halt Command')\n",
    "\n",
    "# overlay the onix photodiode signal in converted time\n",
    "onix_sec_start_time = harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] - 1)\n",
    "onix_sec_start_index = np.where(analog_clock >= onix_sec_start_time)[0][0]\n",
    "\n",
    "onix_sec_stop_time = harp_to_onix_clock(block_halts.iloc[idx+1][\"Seconds\"])\n",
    "onix_sec_stop_index = np.where(analog_clock >= onix_sec_stop_time)[0][0]\n",
    "plt.plot(onix_to_harp_timestamp(analog_clock[onix_sec_start_index:onix_sec_stop_index]), analog_data[onix_sec_start_index:onix_sec_stop_index, 0], label='Photodiode')\n",
    "\n",
    "# overlay photometry\n",
    "photometry_sec_start_time = onix_time_to_photometry(onix_sec_start_time)\n",
    "photometry_sec_stop_time = onix_time_to_photometry(onix_sec_stop_time)\n",
    "photometry_sec = photometry[0].loc[(photometry[0].index >= photometry_sec_start_time) & (photometry[0].index <= photometry_sec_stop_time)]\n",
    "\n",
    "plt.plot(photometry_to_harp_time(photometry_sec.index), photometry_sec['CH1-410'], label='CH1-410')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Function to get memory usage of all variables in MB\n",
    "def get_all_memory_usage():\n",
    "    memory_usage = {var: sys.getsizeof(value) for var, value in globals().items()}\n",
    "    sorted_memory_usage = sorted(memory_usage.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"Variable Memory Usage (in MB):\")\n",
    "    for var, size in sorted_memory_usage:\n",
    "        print(f\"{var}: {size / (1024**2):.2f} MB\")\n",
    "\n",
    "# Call function to display memory usage\n",
    "get_all_memory_usage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "aeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
