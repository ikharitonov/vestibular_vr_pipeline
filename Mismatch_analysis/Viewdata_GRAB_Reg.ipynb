{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# View GRAB mismatch regular and closed loop data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from analysis_functions import *\n",
    "from model_functions import *\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunTresholdDict = {'B3M1': 145, 'B3M2': 295, 'B3M3': 325, 'B2M4': 110, 'B2M5': 180}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAB_Reg_1 = pd.read_csv('/Path/To/Session/csvfile.csv')#, dtype=dtype_dict)\n",
    "GRAB_Reg_2 = pd.read_csv('/Path/To/Session/csvfile.csv'')#, dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure the index provides inforamtion of seconds since start\n",
    "GRAB_Reg_1.set_index('Seconds', inplace=True)\n",
    "GRAB_Reg_2.set_index('Seconds', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure theres a column for session number:\n",
    "if 'session' not in GRAB_Reg_1.columns:\n",
    "    GRAB_Reg_1['Session'] = 'day1'\n",
    "if 'session' not in GRAB_Reg_2.columns:\n",
    "    GRAB_Reg_2['Session'] = 'day2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have a look that the data is as expected\n",
    "GRAB_Reg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaning event name to halt and making it so that its True when there is a halt\n",
    "#GRAB_Reg_1.loc[:, 'event'] = GRAB_Reg_1['event'].replace({False: True, True: False})\n",
    "GRAB_Reg_1.rename(columns = {'event': 'halt'}, inplace = True)\n",
    "GRAB_Reg_2.rename(columns = {'event': 'halt'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that the same mice are in the datsets\n",
    "print(GRAB_Reg_1.mouseID.unique())\n",
    "print(GRAB_Reg_2.mouseID.unique())\n",
    "names = GRAB_Reg_2.mouseID.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# View session data\n",
    "- Loop through the mouse names present in one of the dataframes (ideally they should be the same)\n",
    "- save a variable where each session is saved for the current mouse\n",
    "- use the view_session_mouse() funciton from analysis_functions.py to plot the Delta F/F 470 fluorescence and movement in X direction with halts in grey, and session blocks marked in colors.\n",
    "- Can also add other column names to the plotlist, like eye movements and other fluorescent traces\n",
    "- This is mostly to get an impression of the overall data trends.\n",
    "\n",
    "Move the function into this file to test it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse in GRAB_Reg_1.mouseID.unique():\n",
    "    mousedata = {'session 1':GRAB_Reg_1.loc[GRAB_Reg_1.mouseID == mouse], 'session 2':GRAB_Reg_2.loc[GRAB_Reg_2.mouseID == mouse]}\n",
    "    fig, ax = view_session_mouse(mousedata, mouse)\n",
    "    fig.savefig(f'Figures/GRAB{mouse}_view_alignment.png', format = 'png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Filter with respect to blocks\n",
    "Use the function: filter_data(data, filters = []). \n",
    "Ensure that therere is a filter in the filterdict within the function that corresponds to the blocks and other column specified values that you want to filter by.\n",
    "\n",
    "You can add filters by adding lines to the dict of this format:\n",
    "    'filter key name': ['Relevant column name', Relevant row values to filter],\n",
    "\n",
    "Add the same filters to the dict you define below\n",
    "\n",
    "* Allways filter by mouse in addition to other filters, if the input data includes multiple animal recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter mice to get unique indexes\n",
    "\n",
    "# first make the dict structure\n",
    "mouse_data = {'session 1':{'closedloop': {},'regular': {}, 'no_mismatch':{}}, 'session 2': {'closedloop': {},'regular': {}, 'no_mismatch':{}}}\n",
    "\n",
    "#Then assign mouse by mouse with filtered data to the dict\n",
    "for mouse in GRAB_Reg_1.mouseID.unique():\n",
    "    mouse_data['session 1']['closedloop'][mouse] = filter_data(GRAB_Reg_1, filters = [mouse, 'closed_block'])\n",
    "    mouse_data['session 1']['regular'][mouse] = filter_data(GRAB_Reg_1, filters = [mouse, 'regular_block'])\n",
    "    mouse_data['session 1']['no_mismatch'][mouse] = filter_data(GRAB_Reg_1, filters = [mouse, 'normal_block'])\n",
    "    \n",
    "for mouse in GRAB_Reg_2.mouseID.unique():\n",
    "    mouse_data['session 2']['closedloop'][mouse] = filter_data(GRAB_Reg_2, filters = [mouse, 'closed_block'])\n",
    "    mouse_data['session 2']['regular'][mouse] = filter_data(GRAB_Reg_2, filters = [mouse, 'regular_block'])\n",
    "    mouse_data['session 2']['no_mismatch'][mouse] = filter_data(GRAB_Reg_2, filters = [mouse, 'normal_block'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# Align data and save to dict\n",
    "Run process_mouse_data which will call align_to_event_start and align traces and structure tham into a dictionary.\n",
    "Specify:\n",
    "* The trace columns to align and not baseline\n",
    "* The trace columns to align and basline (can be the same as the former)\n",
    "* The event column (bool column, halt, No_halt, or other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input data (assuming `aligned_data` is structured as needed)\n",
    "trace_columns_to_baseline = ['470_dfF']  # Columns to baseline\n",
    "trace_columns_no_baseline = ['movementY', 'movementX']  # Columns to leave unaltered\n",
    "event_col = 'halt'\n",
    "\n",
    "# Process the data\n",
    "aligned_data = process_mouse_data(mouse_data, trace_columns_to_baseline, trace_columns_no_baseline, event_col, [1, 2])\n",
    "\n",
    "event_col = 'No_halt'\n",
    "aligned_data_nohalt = process_mouse_data(mouse_data, trace_columns_to_baseline, trace_columns_no_baseline, event_col, [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_data['session 1']['closedloop'][names[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_compare_blocks(aligned_data['session 1'], '470_dfF_bsl')\n",
    "plot_compare_blocks(aligned_data['session 2'], '470_dfF_bsl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_compare_blocks(aligned_data['session 1'], 'movementX')\n",
    "plot_compare_blocks(aligned_data['session 2'], 'movementX')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Plot across mouse means\n",
    "Make dicts with mouse mean data depending on session and blocks, and make also a dict with the controls.\n",
    "\n",
    "Use these to plot the across mouse means using the plot_mean_across_blocks function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_mean_session_data = mouse_mean_bsl_data(aligned_data, '470_dfF_bsl')\n",
    "mouse_mean_control_data = mouse_mean_bsl_data(aligned_data_nohalt, '470_dfF_bsl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "\n",
    "session1_blocks = {'closedloop': mouse_mean_session_data['session 1']['closedloop'],\n",
    "                  'regular': mouse_mean_session_data['session 1']['regular']}\n",
    "control1_blocks = {'closedloop': mouse_mean_control_data['session 1']['closedloop']}\n",
    "\n",
    "session2_blocks = {'closedloop': mouse_mean_session_data['session 2']['closedloop'],\n",
    "                  'regular': mouse_mean_ession_data['session 2']['regular']}\n",
    "control2_blocks = {'closedloop': mouse_mean_control_data['session 2']['closedloop']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining plotting dicts for relevant blocks\n",
    "session1_blocks = {'closedloop': mouse_mean_session_data['session 1']['closedloop'],\n",
    "                  'regular': mouse_mean_session_data['session 1']['regular_block']}\n",
    "control1_blocks = {'closedloop': mouse_mean_control_data['session 1']['closedloop'],\n",
    "                  'no_mismatch': mouse_mean_session_data['session 1']['normal_block']}\n",
    "\n",
    "session2_blocks = {'closedloop': mouse_mean_session_data['session 2']['closedloop'],\n",
    "                  'regular': mouse_mean_session_data['session 2']['regular_block']}\n",
    "\n",
    "control2_blocks = {'closedloop': mouse_mean_control_data['session 2']['closedloop'], \n",
    "                  'no_mismatch': mouse_mean_session_data['session 2']['normal_block']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the data\n",
    "plot_mean_across_blocks(session1_blocks, control1_blocks, title=\"Session 1 blocks\")\n",
    "plot_mean_across_blocks(session2_blocks, control1_blocks, title=\"Session 2 blocks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "# Compute statistics\n",
    "Use the compute_trace_statistics to get some paramters from the data. \n",
    "It will return the peak, mean, median and standard deviation for each aligned trace chunk during the time windows 0-1s, 1-2s, and -1-0s.\n",
    "* Specify the aligned trace that you want statistics for\n",
    "* In addition you can specify some other traces for which you will get the mean during, after, and before (same time intervals)\n",
    "\n",
    "* Consider doing this for multiple main traces. Then add a column named for example 'trace' where the main trace name is the value of each row. Combe them all in one df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the main trace and co-traces\n",
    "main_trace = \"470_dfF_bsl\"\n",
    "co_traces = [\"movementX\", \"movementY\"]\n",
    "ranges = [(-1, 0), (0, 1), (1, 2)]\n",
    "\n",
    "# Compute statistics\n",
    "stats_470_main_df = compute_trace_statistics(aligned_data,trace=main_trace,co_traces=co_traces,ranges=ranges,)\n",
    "\n",
    "\n",
    "stats_470_nohalt_df = compute_trace_statistics(aligned_data_nohalt,trace=main_trace,co_traces=co_traces,ranges=ranges,)\n",
    "# Before combinind datasets, introduce a column to seperate the types of data. \n",
    "# Can also be control True and False or other specific event that makes the datsets different\n",
    "stats_470_main_df['halt'] = True\n",
    "stats_470_nohalt_df['halt'] = False\n",
    "\n",
    "# Combine both datasets \n",
    "all_470_stats_df = pd.concat([stats_470_main_df, stats_470_nohalt_df], ignore_index=True)\n",
    "all_470_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_470_stats_df.to_csv('saved_data/GRAB_RegMM_all_470_stats_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Consider adding to the fitted model a continous variable which is the time column\n",
    "#EventTime should currently be seconds from session start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "##  Possible: Look for correlation between running and fluorescence changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = filter_data(GRAB_Reg_1, [names[0], 'day1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Pearson correlation\n",
    "pearson_corr, pearson_pval = pearsonr(subset['movementX'], subset['470_dfF'])\n",
    "\n",
    "# Compute Spearman correlation (handles nonlinear relationships better)\n",
    "spearman_corr, spearman_pval = spearmanr(subset['movementX'], subset['470_dfF'])\n",
    "\n",
    "print(f\"Pearson correlation: {pearson_corr}, p-value: {pearson_pval}\")\n",
    "print(f\"Spearman correlation: {spearman_corr}, p-value: {spearman_pval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled = subset.sample(10000, random_state=9)  # Sample 10,000 rows\n",
    "pearson_corr, pearson_pval = pearsonr(resampled['movementX'], resampled['470_dfF'])\n",
    "spearman_corr, spearman_pval = spearmanr(resampled['movementX'], resampled['470_dfF'])\n",
    "print(f\"Subset Pearson correlation: {pearson_corr}, p-value: {pearson_pval}\")\n",
    "print(f\"Subset Spearman correlation: {spearman_corr}, p-value: {spearman_pval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon_env_3",
   "language": "python",
   "name": "aeon_env_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
