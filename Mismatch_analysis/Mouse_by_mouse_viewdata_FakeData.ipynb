{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# View Fake Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from harp_resources import process, utils\n",
    "from analysis_functions import *\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import io\n",
    "#pip install import-ipynb\n",
    "import import_ipynb\n",
    "# Create a context manager to suppress output\n",
    "f = io.StringIO()\n",
    "with contextlib.redirect_stdout(f), contextlib.redirect_stderr(f):\n",
    "    from Test_streams_make_and_save import df_1, df_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fake_1 = pd.read_csv('Fake_data_session1.csv', dtype=dtype_dict)\n",
    "Fake_2 = pd.read_csv('Fake_data_session2.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaning event name to halt and making it so that its True when there is a halt\n",
    "#Fake_1.loc[:, 'event'] = Fake_1['event'].replace({False: True, True: False})\n",
    "Fake_1.rename(columns = {'event': 'halt'}, inplace = True)\n",
    "Fake_2.rename(columns = {'event': 'halt'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure the index provides inforamtion of seconds since start\n",
    "Fake_1.set_index('Seconds', inplace=True)\n",
    "Fake_2.set_index('Seconds', inplace=True)\n",
    "# Theres only photomotry information from 15 seconds due to bleaching\n",
    "Fake_1 = Fake_1.loc[ Fake_1.index>30]\n",
    "Fake_2 = Fake_2.loc[ Fake_2.index>30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_session_mouse(mousedata_dict, mouse):\n",
    "    print('\\033[1m' + f'Plotted traces for {mouse}' + '\\033[0m')\n",
    "    \n",
    "    plotlist = ['470_dfF', 'movementX']\n",
    "    fig, ax = plt.subplots(len(plotlist), len(mousedata_dict), figsize=(15, 10), sharex=True)  # sharex=True for a shared x-axis\n",
    "    \n",
    "    for s, (session, session_data) in enumerate(mousedata_dict.items()):\n",
    "        \n",
    "        # Getting the mouse-specific data from the session\n",
    "        time = session_data.index\n",
    "        event = session_data.halt\n",
    "        color = ['forestgreen', 'blue']\n",
    "    \n",
    "        # Iterate over the traces in plotlist and plot each on a new row\n",
    "        for i, trace in enumerate(plotlist):\n",
    "            ax[i, s].plot(time, session_data[trace], color=color[i])\n",
    "            ax[i, s].set_title(f\"{trace} - {session}\")\n",
    "            \n",
    "            # Plot shaded areas for each halt event\n",
    "            ymin, ymax = ax[i, s].get_ylim()\n",
    "            #halt = ax[i, s].fill_between(time, ymin, ymax, where=event, color='grey', alpha=0.3)\n",
    "            halt = ax[i, s].fill_between(Fake_1['halt'].index, 0, 1, where=Fake_1['halt'].values, \n",
    "                     facecolor=\"gray\", alpha=0.3)\n",
    "        \n",
    "        # Plot annotations for different blocks\n",
    "        block_colors = ['lightsteelblue', 'lightcoral', 'forestgreen']\n",
    "        colorcount = 0\n",
    "        for col in session_data:\n",
    "            if '_block' in col:\n",
    "                start = session_data.loc[session_data[col] == True].index[0]\n",
    "                end = session_data.loc[session_data[col] == True].index[-1]\n",
    "        \n",
    "                min_time, max_time = ax[0, s].get_xlim()\n",
    "                norm_start = norm(start, min_time, max_time)\n",
    "                norm_end = norm(end, min_time, max_time)\n",
    "                \n",
    "                # Add rectangles with alpha=0.1 to each trace subplot in this session\n",
    "                for i in range(len(plotlist)):\n",
    "                    ax[i, s].add_patch(Rectangle(\n",
    "                        (norm_start, 0), norm_end - norm_start, 1, \n",
    "                        facecolor=block_colors[colorcount], alpha=0.1, clip_on=False, transform=ax[i, s].transAxes\n",
    "                    ))\n",
    "\n",
    "                # Add labels at the bottom of the last plot\n",
    "                ax[-1, s].text(norm_start + 0.05, -0.2, col, transform=ax[-1, s].transAxes,\n",
    "                               fontsize=10, verticalalignment='top')\n",
    "                ax[-1, s].add_patch(Rectangle(\n",
    "                    (norm_start, -0.15), norm_end - norm_start, -0.2, \n",
    "                    facecolor=block_colors[colorcount], alpha=0.5, clip_on=False, transform=ax[-1, s].transAxes))\n",
    "                \n",
    "                colorcount += 1\n",
    "\n",
    "    halt.set_label('halts')\n",
    "    # Create one legend for the figure\n",
    "    fig.legend(fontsize=12)\n",
    "    \n",
    "    # Update font size and layout\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    fig.tight_layout(pad=1.08)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that the same mice are in the datsets\n",
    "print(Fake_1.mouseID.unique())\n",
    "print(Fake_2.mouseID.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse in Fake_1.mouseID.unique():\n",
    "    mousedata = {'session 1':Fake_1.loc[Fake_1.mouseID == mouse], 'session 2':Fake_2.loc[Fake_2.mouseID == mouse]}\n",
    "    view_session_mouse(mousedata, mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.Seconds -762869.6790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df_1 = Fake_1[['movementX', 'movementY', '470_dfF', 'halt']].copy()\n",
    "fake_df_2 = Fake_2[['movementX', 'movementY', '470_dfF', 'halt']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_transformation(original_df, new_df):\n",
    "    # 1. Verify column mappings\n",
    "    column_mapping = {\n",
    "        'OpticalTrackingRead0X(46)': 'movementX',\n",
    "        'OpticalTrackingRead0Y(46)': 'movementY',\n",
    "        'CH1-470': '470_dfF',\n",
    "        'Photodiode': 'halt'\n",
    "    }\n",
    "    for original_col, new_col in column_mapping.items():\n",
    "        assert new_col in new_df.columns, f\"Missing column: {new_col}\"\n",
    "        print(f\"Column mapping verified: {original_col} -> {new_col}\")\n",
    "\n",
    "    # 2. Filter out the first 30 seconds from the original dataframe\n",
    "    start_time = original_df['Seconds'].iloc[0] + 30.000\n",
    "    filtered_original_df = original_df[original_df['Seconds'] >= start_time]\n",
    "\n",
    "    print(f\"Original dataframe filtered to start at {start_time} seconds.\")\n",
    "\n",
    "    # Shift the Seconds column to align with the new dataframe's index\n",
    "    filtered_original_df['Adjusted_Seconds'] = filtered_original_df['Seconds'] - start_time\n",
    "\n",
    "    # 3. Verify downsampling dynamically\n",
    "    # Match the time range of new_df in filtered_original_df\n",
    "    filtered_time_range = filtered_original_df[\n",
    "        (filtered_original_df['Adjusted_Seconds'] >= new_df.index.min()) &\n",
    "        (filtered_original_df['Adjusted_Seconds'] <= new_df.index.max())\n",
    "    ]\n",
    "\n",
    "    print(f\"Filtered original data to time range: {new_df.index.min()} to {new_df.index.max()}.\")\n",
    "\n",
    "    # Calculate the expected number of rows based on step sizes in the new dataframe\n",
    "    observed_interval = np.mean(np.diff(new_df.index))  # Actual interval in new_df\n",
    "    expected_rows = int((filtered_time_range['Adjusted_Seconds'].max() - filtered_time_range['Adjusted_Seconds'].min()) / observed_interval) + 1\n",
    "\n",
    "    print(f\"Observed interval: {observed_interval} seconds\")\n",
    "    print(f\"Expected rows: {expected_rows}, Actual rows in new_df: {len(new_df)}\")\n",
    "\n",
    "    assert abs(len(new_df) - expected_rows) <= 1, f\"Downsampling row count mismatch: Expected {expected_rows}, Got {len(new_df)}\"\n",
    "\n",
    "    print(\"Downsampling verified.\")\n",
    "\n",
    "    # 4. Validate data integrity using interpolation\n",
    "    # Interpolate original data to the new index\n",
    "    interpolated_df = (\n",
    "        filtered_time_range\n",
    "        .set_index('Adjusted_Seconds')\n",
    "        .reindex(new_df.index)\n",
    "        .interpolate()\n",
    "    )\n",
    "\n",
    "    # Compare interpolated data with new dataframe\n",
    "    for original_col, new_col in column_mapping.items():\n",
    "        difference = np.abs(interpolated_df[original_col] - new_df[new_col])\n",
    "        max_diff = difference.max()\n",
    "        assert max_diff < 1e-3, f\"Data integrity check failed for {new_col}: Max difference = {max_diff}\"\n",
    "        print(f\"Data integrity check passed for {new_col}: Max difference = {max_diff:.6f}\")\n",
    "\n",
    "    print(\"All verification checks passed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_transformation(df_2,fake_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "2010589 - 2163590"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "153001/1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "aeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
